{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gna4gIuCs4nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "# === GPU SETUP ===\n",
        "print(\"=== GPU Devices ===\")\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Aktifkan memory growth (menghindari over-allocate di DGX)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# === LOAD DATA ===\n",
        "train_df = pd.read_csv('train.csv')\n",
        "val_df = pd.read_csv('val.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# === PREPROCESSING ===\n",
        "# Encode 'Kategori'\n",
        "all_kategori = pd.concat([train_df['Kategori'], val_df['Kategori'], test_df['Kategori']])\n",
        "le_kat = LabelEncoder().fit(all_kategori)\n",
        "\n",
        "train_df['Kategori_enc'] = le_kat.transform(train_df['Kategori'])\n",
        "val_df['Kategori_enc'] = le_kat.transform(val_df['Kategori'])\n",
        "test_df['Kategori_enc'] = le_kat.transform(test_df['Kategori'])\n",
        "\n",
        "# Scale RPN\n",
        "scaler = StandardScaler().fit(\n",
        "    pd.concat([train_df[['RPN']], val_df[['RPN']], test_df[['RPN']]])\n",
        ")\n",
        "\n",
        "train_df['RPN_scaled'] = scaler.transform(train_df[['RPN']])\n",
        "val_df['RPN_scaled'] = scaler.transform(val_df[['RPN']])\n",
        "test_df['RPN_scaled'] = scaler.transform(test_df[['RPN']])\n",
        "\n",
        "# Input features\n",
        "X_train = train_df[['Kategori_enc', 'RPN_scaled']].values\n",
        "X_val = val_df[['Kategori_enc', 'RPN_scaled']].values\n",
        "X_test = test_df[['Kategori_enc', 'RPN_scaled']].values\n",
        "\n",
        "# Encode target 'Resiko'\n",
        "le_resiko = LabelEncoder().fit(train_df['Resiko'])\n",
        "\n",
        "y_train = to_categorical(le_resiko.transform(train_df['Resiko']))\n",
        "y_val = to_categorical(le_resiko.transform(val_df['Resiko']))\n",
        "y_test = le_resiko.transform(test_df['Resiko'])  # for evaluation\n",
        "y_test_label_names = le_resiko.classes_\n",
        "\n",
        "# === CALLBACKS ===\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(2,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(96, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(80, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(48, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# === TRAINING ===\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=500,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[early_stop, checkpoint])\n",
        "\n",
        "# === PREDIKSI TEST ===\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaaDOxdgs45j",
        "outputId": "000fab3c-de8b-4feb-bab0-2e8b03b8d6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GPU Devices ===\n",
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1748 - loss: 1.8248\n",
            "Epoch 1: val_loss improved from inf to 1.63140, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.1746 - loss: 1.8208 - val_accuracy: 0.1696 - val_loss: 1.6314\n",
            "Epoch 2/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2227 - loss: 1.6683\n",
            "Epoch 2: val_loss improved from 1.63140 to 1.58992, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2227 - loss: 1.6669 - val_accuracy: 0.1730 - val_loss: 1.5899\n",
            "Epoch 3/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2577 - loss: 1.5927\n",
            "Epoch 3: val_loss improved from 1.58992 to 1.57405, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2579 - loss: 1.5901 - val_accuracy: 0.2526 - val_loss: 1.5741\n",
            "Epoch 4/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2888 - loss: 1.5792\n",
            "Epoch 4: val_loss improved from 1.57405 to 1.54574, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2891 - loss: 1.5773 - val_accuracy: 0.2907 - val_loss: 1.5457\n",
            "Epoch 5/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3204 - loss: 1.5079\n",
            "Epoch 5: val_loss improved from 1.54574 to 1.48301, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3214 - loss: 1.5061 - val_accuracy: 0.3460 - val_loss: 1.4830\n",
            "Epoch 6/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3526 - loss: 1.4598\n",
            "Epoch 6: val_loss improved from 1.48301 to 1.47691, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3513 - loss: 1.4603 - val_accuracy: 0.3668 - val_loss: 1.4769\n",
            "Epoch 7/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3751 - loss: 1.4165\n",
            "Epoch 7: val_loss improved from 1.47691 to 1.45359, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3785 - loss: 1.4144 - val_accuracy: 0.4048 - val_loss: 1.4536\n",
            "Epoch 8/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4477 - loss: 1.3747\n",
            "Epoch 8: val_loss improved from 1.45359 to 1.35748, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4464 - loss: 1.3744 - val_accuracy: 0.4567 - val_loss: 1.3575\n",
            "Epoch 9/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4506 - loss: 1.2958\n",
            "Epoch 9: val_loss improved from 1.35748 to 1.27288, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4528 - loss: 1.2942 - val_accuracy: 0.4602 - val_loss: 1.2729\n",
            "Epoch 10/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4442 - loss: 1.2543\n",
            "Epoch 10: val_loss improved from 1.27288 to 1.06414, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4469 - loss: 1.2519 - val_accuracy: 0.6332 - val_loss: 1.0641\n",
            "Epoch 11/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5138 - loss: 1.1500\n",
            "Epoch 11: val_loss improved from 1.06414 to 0.97369, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5149 - loss: 1.1505 - val_accuracy: 0.6747 - val_loss: 0.9737\n",
            "Epoch 12/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5455 - loss: 1.1095\n",
            "Epoch 12: val_loss improved from 0.97369 to 0.87099, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5445 - loss: 1.1105 - val_accuracy: 0.6644 - val_loss: 0.8710\n",
            "Epoch 13/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5547 - loss: 1.0408\n",
            "Epoch 13: val_loss improved from 0.87099 to 0.81357, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5539 - loss: 1.0400 - val_accuracy: 0.6298 - val_loss: 0.8136\n",
            "Epoch 14/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5879 - loss: 0.9963\n",
            "Epoch 14: val_loss improved from 0.81357 to 0.80610, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5890 - loss: 0.9953 - val_accuracy: 0.6747 - val_loss: 0.8061\n",
            "Epoch 15/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5873 - loss: 0.9831\n",
            "Epoch 15: val_loss did not improve from 0.80610\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5865 - loss: 0.9837 - val_accuracy: 0.6194 - val_loss: 0.8123\n",
            "Epoch 16/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 0.9571\n",
            "Epoch 16: val_loss improved from 0.80610 to 0.71423, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6058 - loss: 0.9568 - val_accuracy: 0.6817 - val_loss: 0.7142\n",
            "Epoch 17/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5894 - loss: 0.9150\n",
            "Epoch 17: val_loss improved from 0.71423 to 0.62559, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5895 - loss: 0.9163 - val_accuracy: 0.7924 - val_loss: 0.6256\n",
            "Epoch 18/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6107 - loss: 0.8913\n",
            "Epoch 18: val_loss did not improve from 0.62559\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6106 - loss: 0.8911 - val_accuracy: 0.7163 - val_loss: 0.7079\n",
            "Epoch 19/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6051 - loss: 0.8675\n",
            "Epoch 19: val_loss did not improve from 0.62559\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6060 - loss: 0.8670 - val_accuracy: 0.7612 - val_loss: 0.6298\n",
            "Epoch 20/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6331 - loss: 0.9044\n",
            "Epoch 20: val_loss did not improve from 0.62559\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6357 - loss: 0.8969 - val_accuracy: 0.7163 - val_loss: 0.6761\n",
            "Epoch 21/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6547 - loss: 0.8448\n",
            "Epoch 21: val_loss improved from 0.62559 to 0.55212, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6549 - loss: 0.8430 - val_accuracy: 0.8304 - val_loss: 0.5521\n",
            "Epoch 22/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7033 - loss: 0.7368\n",
            "Epoch 22: val_loss improved from 0.55212 to 0.53811, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7002 - loss: 0.7385 - val_accuracy: 0.8478 - val_loss: 0.5381\n",
            "Epoch 23/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7085 - loss: 0.7395\n",
            "Epoch 23: val_loss improved from 0.53811 to 0.49472, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7077 - loss: 0.7392 - val_accuracy: 0.8651 - val_loss: 0.4947\n",
            "Epoch 24/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6922 - loss: 0.7099\n",
            "Epoch 24: val_loss improved from 0.49472 to 0.46994, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6914 - loss: 0.7117 - val_accuracy: 0.8962 - val_loss: 0.4699\n",
            "Epoch 25/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6513 - loss: 0.7834\n",
            "Epoch 25: val_loss did not improve from 0.46994\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6519 - loss: 0.7845 - val_accuracy: 0.9100 - val_loss: 0.4965\n",
            "Epoch 26/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6320 - loss: 0.8215\n",
            "Epoch 26: val_loss did not improve from 0.46994\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6326 - loss: 0.8194 - val_accuracy: 0.7232 - val_loss: 0.6720\n",
            "Epoch 27/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6655 - loss: 0.7816\n",
            "Epoch 27: val_loss did not improve from 0.46994\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6650 - loss: 0.7808 - val_accuracy: 0.7958 - val_loss: 0.5466\n",
            "Epoch 28/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6958 - loss: 0.7281\n",
            "Epoch 28: val_loss did not improve from 0.46994\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6944 - loss: 0.7286 - val_accuracy: 0.8720 - val_loss: 0.4946\n",
            "Epoch 29/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7000 - loss: 0.6954\n",
            "Epoch 29: val_loss did not improve from 0.46994\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6997 - loss: 0.6957 - val_accuracy: 0.8685 - val_loss: 0.4905\n",
            "Epoch 30/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6807 - loss: 0.7173\n",
            "Epoch 30: val_loss improved from 0.46994 to 0.41497, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6828 - loss: 0.7146 - val_accuracy: 0.9204 - val_loss: 0.4150\n",
            "Epoch 31/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6934 - loss: 0.7077\n",
            "Epoch 31: val_loss did not improve from 0.41497\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6920 - loss: 0.7102 - val_accuracy: 0.9100 - val_loss: 0.4420\n",
            "Epoch 32/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7136 - loss: 0.6855\n",
            "Epoch 32: val_loss improved from 0.41497 to 0.40479, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7119 - loss: 0.6872 - val_accuracy: 0.9239 - val_loss: 0.4048\n",
            "Epoch 33/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6856 - loss: 0.7429\n",
            "Epoch 33: val_loss improved from 0.40479 to 0.39652, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6859 - loss: 0.7417 - val_accuracy: 0.9100 - val_loss: 0.3965\n",
            "Epoch 34/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7230 - loss: 0.6762\n",
            "Epoch 34: val_loss improved from 0.39652 to 0.39100, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7241 - loss: 0.6737 - val_accuracy: 0.9273 - val_loss: 0.3910\n",
            "Epoch 35/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6886 - loss: 0.7537\n",
            "Epoch 35: val_loss did not improve from 0.39100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6917 - loss: 0.7462 - val_accuracy: 0.8547 - val_loss: 0.4163\n",
            "Epoch 36/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6766 - loss: 0.7514\n",
            "Epoch 36: val_loss did not improve from 0.39100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6775 - loss: 0.7494 - val_accuracy: 0.8997 - val_loss: 0.4195\n",
            "Epoch 37/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6804 - loss: 0.7312\n",
            "Epoch 37: val_loss did not improve from 0.39100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6810 - loss: 0.7306 - val_accuracy: 0.8720 - val_loss: 0.4690\n",
            "Epoch 38/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7453 - loss: 0.6292\n",
            "Epoch 38: val_loss did not improve from 0.39100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7440 - loss: 0.6316 - val_accuracy: 0.8893 - val_loss: 0.4051\n",
            "Epoch 39/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7219 - loss: 0.6785\n",
            "Epoch 39: val_loss improved from 0.39100 to 0.38162, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7213 - loss: 0.6793 - val_accuracy: 0.9308 - val_loss: 0.3816\n",
            "Epoch 40/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7175 - loss: 0.6715\n",
            "Epoch 40: val_loss did not improve from 0.38162\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7182 - loss: 0.6704 - val_accuracy: 0.9204 - val_loss: 0.3977\n",
            "Epoch 41/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7379 - loss: 0.6424\n",
            "Epoch 41: val_loss did not improve from 0.38162\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7354 - loss: 0.6464 - val_accuracy: 0.9239 - val_loss: 0.3937\n",
            "Epoch 42/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6991 - loss: 0.7285\n",
            "Epoch 42: val_loss did not improve from 0.38162\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7019 - loss: 0.7215 - val_accuracy: 0.8512 - val_loss: 0.4634\n",
            "Epoch 43/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7484 - loss: 0.6177\n",
            "Epoch 43: val_loss did not improve from 0.38162\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7477 - loss: 0.6197 - val_accuracy: 0.8512 - val_loss: 0.4042\n",
            "Epoch 44/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7544 - loss: 0.6158\n",
            "Epoch 44: val_loss improved from 0.38162 to 0.36780, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7548 - loss: 0.6161 - val_accuracy: 0.8997 - val_loss: 0.3678\n",
            "Epoch 45/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7072 - loss: 0.6668\n",
            "Epoch 45: val_loss improved from 0.36780 to 0.35757, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7074 - loss: 0.6664 - val_accuracy: 0.8927 - val_loss: 0.3576\n",
            "Epoch 46/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7278 - loss: 0.6119\n",
            "Epoch 46: val_loss improved from 0.35757 to 0.35114, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7285 - loss: 0.6125 - val_accuracy: 0.9066 - val_loss: 0.3511\n",
            "Epoch 47/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7665 - loss: 0.5832\n",
            "Epoch 47: val_loss did not improve from 0.35114\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7638 - loss: 0.5877 - val_accuracy: 0.8720 - val_loss: 0.3670\n",
            "Epoch 48/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7201 - loss: 0.6658\n",
            "Epoch 48: val_loss did not improve from 0.35114\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7215 - loss: 0.6606 - val_accuracy: 0.9100 - val_loss: 0.3598\n",
            "Epoch 49/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7364 - loss: 0.6369\n",
            "Epoch 49: val_loss did not improve from 0.35114\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7336 - loss: 0.6405 - val_accuracy: 0.8789 - val_loss: 0.3913\n",
            "Epoch 50/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7422 - loss: 0.6148\n",
            "Epoch 50: val_loss did not improve from 0.35114\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7425 - loss: 0.6145 - val_accuracy: 0.8339 - val_loss: 0.4616\n",
            "Epoch 51/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7644 - loss: 0.5702\n",
            "Epoch 51: val_loss improved from 0.35114 to 0.32537, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7644 - loss: 0.5720 - val_accuracy: 0.9204 - val_loss: 0.3254\n",
            "Epoch 52/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7549 - loss: 0.6106\n",
            "Epoch 52: val_loss did not improve from 0.32537\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7541 - loss: 0.6093 - val_accuracy: 0.8754 - val_loss: 0.3882\n",
            "Epoch 53/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7380 - loss: 0.6032\n",
            "Epoch 53: val_loss did not improve from 0.32537\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7412 - loss: 0.5972 - val_accuracy: 0.9135 - val_loss: 0.3274\n",
            "Epoch 54/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.5235\n",
            "Epoch 54: val_loss improved from 0.32537 to 0.31842, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7913 - loss: 0.5262 - val_accuracy: 0.8893 - val_loss: 0.3184\n",
            "Epoch 55/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7848 - loss: 0.5557\n",
            "Epoch 55: val_loss did not improve from 0.31842\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7835 - loss: 0.5571 - val_accuracy: 0.8651 - val_loss: 0.3748\n",
            "Epoch 56/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7572 - loss: 0.6167\n",
            "Epoch 56: val_loss did not improve from 0.31842\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7564 - loss: 0.6158 - val_accuracy: 0.9100 - val_loss: 0.3552\n",
            "Epoch 57/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7599 - loss: 0.5739\n",
            "Epoch 57: val_loss improved from 0.31842 to 0.31812, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7597 - loss: 0.5736 - val_accuracy: 0.8962 - val_loss: 0.3181\n",
            "Epoch 58/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7350 - loss: 0.6408\n",
            "Epoch 58: val_loss did not improve from 0.31812\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7351 - loss: 0.6403 - val_accuracy: 0.8824 - val_loss: 0.3380\n",
            "Epoch 59/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7969 - loss: 0.5440\n",
            "Epoch 59: val_loss improved from 0.31812 to 0.28960, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7968 - loss: 0.5440 - val_accuracy: 0.9170 - val_loss: 0.2896\n",
            "Epoch 60/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7665 - loss: 0.5567\n",
            "Epoch 60: val_loss did not improve from 0.28960\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7659 - loss: 0.5576 - val_accuracy: 0.8581 - val_loss: 0.3697\n",
            "Epoch 61/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7666 - loss: 0.5442\n",
            "Epoch 61: val_loss improved from 0.28960 to 0.28619, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7658 - loss: 0.5467 - val_accuracy: 0.9066 - val_loss: 0.2862\n",
            "Epoch 62/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7851 - loss: 0.5354\n",
            "Epoch 62: val_loss did not improve from 0.28619\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7834 - loss: 0.5385 - val_accuracy: 0.9066 - val_loss: 0.2872\n",
            "Epoch 63/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7674 - loss: 0.5536\n",
            "Epoch 63: val_loss did not improve from 0.28619\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7675 - loss: 0.5540 - val_accuracy: 0.9066 - val_loss: 0.2896\n",
            "Epoch 64/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7421 - loss: 0.5967\n",
            "Epoch 64: val_loss did not improve from 0.28619\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7434 - loss: 0.5953 - val_accuracy: 0.8927 - val_loss: 0.3704\n",
            "Epoch 65/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7444 - loss: 0.5955\n",
            "Epoch 65: val_loss did not improve from 0.28619\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7463 - loss: 0.5930 - val_accuracy: 0.8927 - val_loss: 0.3265\n",
            "Epoch 66/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8122 - loss: 0.5109\n",
            "Epoch 66: val_loss did not improve from 0.28619\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8118 - loss: 0.5112 - val_accuracy: 0.9031 - val_loss: 0.3020\n",
            "Epoch 67/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7785 - loss: 0.5220\n",
            "Epoch 67: val_loss did not improve from 0.28619\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7787 - loss: 0.5224 - val_accuracy: 0.9239 - val_loss: 0.2960\n",
            "Epoch 68/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7748 - loss: 0.5323\n",
            "Epoch 68: val_loss improved from 0.28619 to 0.28247, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7746 - loss: 0.5337 - val_accuracy: 0.8927 - val_loss: 0.2825\n",
            "Epoch 69/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7714 - loss: 0.5357\n",
            "Epoch 69: val_loss improved from 0.28247 to 0.26858, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7708 - loss: 0.5372 - val_accuracy: 0.9308 - val_loss: 0.2686\n",
            "Epoch 70/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7990 - loss: 0.5105\n",
            "Epoch 70: val_loss did not improve from 0.26858\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7968 - loss: 0.5145 - val_accuracy: 0.8443 - val_loss: 0.3707\n",
            "Epoch 71/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8008 - loss: 0.5018\n",
            "Epoch 71: val_loss improved from 0.26858 to 0.25091, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7995 - loss: 0.5031 - val_accuracy: 0.9481 - val_loss: 0.2509\n",
            "Epoch 72/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7940 - loss: 0.5177\n",
            "Epoch 72: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7937 - loss: 0.5182 - val_accuracy: 0.9446 - val_loss: 0.2744\n",
            "Epoch 73/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7589 - loss: 0.5303\n",
            "Epoch 73: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7615 - loss: 0.5307 - val_accuracy: 0.8408 - val_loss: 0.3893\n",
            "Epoch 74/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7708 - loss: 0.5791\n",
            "Epoch 74: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7714 - loss: 0.5773 - val_accuracy: 0.8927 - val_loss: 0.2798\n",
            "Epoch 75/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7575 - loss: 0.6037\n",
            "Epoch 75: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7583 - loss: 0.6018 - val_accuracy: 0.9170 - val_loss: 0.2696\n",
            "Epoch 76/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7941 - loss: 0.4974\n",
            "Epoch 76: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7946 - loss: 0.4979 - val_accuracy: 0.9412 - val_loss: 0.2638\n",
            "Epoch 77/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.5006\n",
            "Epoch 77: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8075 - loss: 0.5024 - val_accuracy: 0.9066 - val_loss: 0.2906\n",
            "Epoch 78/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7940 - loss: 0.5379\n",
            "Epoch 78: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7932 - loss: 0.5412 - val_accuracy: 0.8824 - val_loss: 0.3254\n",
            "Epoch 79/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6831 - loss: 0.7103\n",
            "Epoch 79: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6850 - loss: 0.7088 - val_accuracy: 0.6505 - val_loss: 0.9191\n",
            "Epoch 80/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7106 - loss: 0.7037\n",
            "Epoch 80: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7109 - loss: 0.7022 - val_accuracy: 0.7855 - val_loss: 0.5011\n",
            "Epoch 81/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7219 - loss: 0.6538\n",
            "Epoch 81: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7207 - loss: 0.6547 - val_accuracy: 0.8547 - val_loss: 0.4039\n",
            "Epoch 82/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7468 - loss: 0.6082\n",
            "Epoch 82: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7481 - loss: 0.6054 - val_accuracy: 0.8858 - val_loss: 0.3503\n",
            "Epoch 83/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7160 - loss: 0.6714\n",
            "Epoch 83: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7217 - loss: 0.6619 - val_accuracy: 0.9170 - val_loss: 0.3094\n",
            "Epoch 84/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7573 - loss: 0.5740\n",
            "Epoch 84: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7586 - loss: 0.5709 - val_accuracy: 0.9273 - val_loss: 0.3048\n",
            "Epoch 85/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7712 - loss: 0.5637\n",
            "Epoch 85: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7713 - loss: 0.5632 - val_accuracy: 0.8927 - val_loss: 0.3278\n",
            "Epoch 86/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7706 - loss: 0.5372\n",
            "Epoch 86: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7722 - loss: 0.5381 - val_accuracy: 0.7336 - val_loss: 0.4876\n",
            "Epoch 87/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7607 - loss: 0.5492\n",
            "Epoch 87: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7611 - loss: 0.5481 - val_accuracy: 0.9239 - val_loss: 0.2670\n",
            "Epoch 88/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7816 - loss: 0.5466\n",
            "Epoch 88: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7789 - loss: 0.5509 - val_accuracy: 0.9135 - val_loss: 0.2787\n",
            "Epoch 89/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7909 - loss: 0.5048\n",
            "Epoch 89: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7907 - loss: 0.5054 - val_accuracy: 0.8962 - val_loss: 0.3126\n",
            "Epoch 90/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7616 - loss: 0.5830\n",
            "Epoch 90: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7619 - loss: 0.5847 - val_accuracy: 0.8893 - val_loss: 0.3347\n",
            "Epoch 91/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7833 - loss: 0.5513\n",
            "Epoch 91: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7832 - loss: 0.5522 - val_accuracy: 0.8858 - val_loss: 0.3308\n",
            "Epoch 92/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7483 - loss: 0.6101\n",
            "Epoch 92: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7491 - loss: 0.6096 - val_accuracy: 0.9446 - val_loss: 0.3015\n",
            "Epoch 93/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7397 - loss: 0.5981\n",
            "Epoch 93: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7414 - loss: 0.5944 - val_accuracy: 0.9308 - val_loss: 0.2794\n",
            "Epoch 94/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7702 - loss: 0.5323\n",
            "Epoch 94: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7662 - loss: 0.5395 - val_accuracy: 0.9031 - val_loss: 0.3170\n",
            "Epoch 95/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7662 - loss: 0.5688\n",
            "Epoch 95: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7680 - loss: 0.5662 - val_accuracy: 0.9135 - val_loss: 0.2930\n",
            "Epoch 96/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7798 - loss: 0.5150\n",
            "Epoch 96: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7777 - loss: 0.5191 - val_accuracy: 0.9239 - val_loss: 0.2777\n",
            "Epoch 97/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7785 - loss: 0.5042\n",
            "Epoch 97: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7784 - loss: 0.5046 - val_accuracy: 0.9239 - val_loss: 0.2719\n",
            "Epoch 98/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.5122\n",
            "Epoch 98: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7819 - loss: 0.5137 - val_accuracy: 0.9343 - val_loss: 0.2789\n",
            "Epoch 99/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7858 - loss: 0.5446\n",
            "Epoch 99: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7841 - loss: 0.5472 - val_accuracy: 0.9100 - val_loss: 0.3037\n",
            "Epoch 100/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8056 - loss: 0.5153\n",
            "Epoch 100: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8032 - loss: 0.5191 - val_accuracy: 0.9343 - val_loss: 0.2557\n",
            "Epoch 101/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7774 - loss: 0.5545\n",
            "Epoch 101: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7764 - loss: 0.5557 - val_accuracy: 0.9412 - val_loss: 0.2608\n",
            "Epoch 102/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8183 - loss: 0.4856\n",
            "Epoch 102: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8147 - loss: 0.4884 - val_accuracy: 0.9239 - val_loss: 0.2675\n",
            "Epoch 103/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8021 - loss: 0.5086\n",
            "Epoch 103: val_loss did not improve from 0.25091\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8028 - loss: 0.5077 - val_accuracy: 0.9343 - val_loss: 0.2668\n",
            "Epoch 104/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8061 - loss: 0.4867\n",
            "Epoch 104: val_loss improved from 0.25091 to 0.23585, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8043 - loss: 0.4895 - val_accuracy: 0.9343 - val_loss: 0.2359\n",
            "Epoch 105/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8131 - loss: 0.4615\n",
            "Epoch 105: val_loss improved from 0.23585 to 0.22014, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8137 - loss: 0.4615 - val_accuracy: 0.9446 - val_loss: 0.2201\n",
            "Epoch 106/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8177 - loss: 0.4722\n",
            "Epoch 106: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8177 - loss: 0.4772 - val_accuracy: 0.9273 - val_loss: 0.2416\n",
            "Epoch 107/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4621\n",
            "Epoch 107: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8099 - loss: 0.4636 - val_accuracy: 0.9204 - val_loss: 0.2469\n",
            "Epoch 108/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7855 - loss: 0.5212\n",
            "Epoch 108: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7869 - loss: 0.5198 - val_accuracy: 0.9412 - val_loss: 0.2383\n",
            "Epoch 109/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.4800\n",
            "Epoch 109: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8040 - loss: 0.4797 - val_accuracy: 0.9412 - val_loss: 0.2428\n",
            "Epoch 110/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7941 - loss: 0.5262\n",
            "Epoch 110: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7951 - loss: 0.5258 - val_accuracy: 0.9516 - val_loss: 0.2269\n",
            "Epoch 111/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8161 - loss: 0.4731\n",
            "Epoch 111: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8166 - loss: 0.4740 - val_accuracy: 0.9412 - val_loss: 0.2298\n",
            "Epoch 112/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8012 - loss: 0.5186\n",
            "Epoch 112: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8001 - loss: 0.5196 - val_accuracy: 0.9066 - val_loss: 0.2578\n",
            "Epoch 113/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.4677\n",
            "Epoch 113: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8107 - loss: 0.4682 - val_accuracy: 0.8962 - val_loss: 0.2744\n",
            "Epoch 114/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8208 - loss: 0.4802\n",
            "Epoch 114: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8181 - loss: 0.4848 - val_accuracy: 0.8893 - val_loss: 0.2754\n",
            "Epoch 115/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.4756\n",
            "Epoch 115: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7998 - loss: 0.4779 - val_accuracy: 0.8858 - val_loss: 0.3199\n",
            "Epoch 116/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7966 - loss: 0.5051\n",
            "Epoch 116: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7974 - loss: 0.5046 - val_accuracy: 0.9100 - val_loss: 0.2551\n",
            "Epoch 117/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7753 - loss: 0.5719\n",
            "Epoch 117: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7751 - loss: 0.5698 - val_accuracy: 0.6436 - val_loss: 0.7872\n",
            "Epoch 118/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7966 - loss: 0.4965\n",
            "Epoch 118: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7961 - loss: 0.4983 - val_accuracy: 0.9066 - val_loss: 0.2595\n",
            "Epoch 119/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7967 - loss: 0.5359\n",
            "Epoch 119: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7971 - loss: 0.5339 - val_accuracy: 0.9066 - val_loss: 0.2742\n",
            "Epoch 120/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8073 - loss: 0.4879\n",
            "Epoch 120: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8071 - loss: 0.4883 - val_accuracy: 0.9170 - val_loss: 0.2718\n",
            "Epoch 121/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8258 - loss: 0.4752\n",
            "Epoch 121: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8246 - loss: 0.4759 - val_accuracy: 0.9066 - val_loss: 0.2589\n",
            "Epoch 122/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8124 - loss: 0.4762\n",
            "Epoch 122: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8110 - loss: 0.4779 - val_accuracy: 0.9204 - val_loss: 0.2424\n",
            "Epoch 123/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8151 - loss: 0.4752\n",
            "Epoch 123: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8151 - loss: 0.4752 - val_accuracy: 0.9135 - val_loss: 0.2547\n",
            "Epoch 124/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8016 - loss: 0.5420\n",
            "Epoch 124: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8002 - loss: 0.5424 - val_accuracy: 0.8962 - val_loss: 0.2777\n",
            "Epoch 125/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7999 - loss: 0.4779\n",
            "Epoch 125: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7999 - loss: 0.4769 - val_accuracy: 0.9066 - val_loss: 0.2747\n",
            "Epoch 126/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7721 - loss: 0.5147\n",
            "Epoch 126: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7750 - loss: 0.5119 - val_accuracy: 0.9239 - val_loss: 0.2385\n",
            "Epoch 127/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8039 - loss: 0.4855\n",
            "Epoch 127: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8065 - loss: 0.4820 - val_accuracy: 0.9412 - val_loss: 0.2247\n",
            "Epoch 128/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8148 - loss: 0.4733\n",
            "Epoch 128: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8146 - loss: 0.4749 - val_accuracy: 0.9204 - val_loss: 0.2430\n",
            "Epoch 129/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.4977\n",
            "Epoch 129: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8031 - loss: 0.4971 - val_accuracy: 0.9066 - val_loss: 0.2633\n",
            "Epoch 130/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7805 - loss: 0.5326\n",
            "Epoch 130: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7814 - loss: 0.5318 - val_accuracy: 0.9446 - val_loss: 0.2249\n",
            "Epoch 131/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8191 - loss: 0.4413\n",
            "Epoch 131: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8192 - loss: 0.4409 - val_accuracy: 0.8893 - val_loss: 0.2526\n",
            "Epoch 132/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8227 - loss: 0.4607\n",
            "Epoch 132: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8230 - loss: 0.4609 - val_accuracy: 0.9273 - val_loss: 0.2220\n",
            "Epoch 133/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8126 - loss: 0.4486\n",
            "Epoch 133: val_loss did not improve from 0.22014\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8135 - loss: 0.4502 - val_accuracy: 0.8893 - val_loss: 0.2619\n",
            "Epoch 134/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8481 - loss: 0.4093\n",
            "Epoch 134: val_loss improved from 0.22014 to 0.20840, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8469 - loss: 0.4117 - val_accuracy: 0.9170 - val_loss: 0.2084\n",
            "Epoch 135/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8365 - loss: 0.4599\n",
            "Epoch 135: val_loss did not improve from 0.20840\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8362 - loss: 0.4589 - val_accuracy: 0.9066 - val_loss: 0.2295\n",
            "Epoch 136/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8391 - loss: 0.4178\n",
            "Epoch 136: val_loss did not improve from 0.20840\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8381 - loss: 0.4212 - val_accuracy: 0.8997 - val_loss: 0.2354\n",
            "Epoch 137/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8082 - loss: 0.4720\n",
            "Epoch 137: val_loss improved from 0.20840 to 0.19765, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8088 - loss: 0.4714 - val_accuracy: 0.9239 - val_loss: 0.1976\n",
            "Epoch 138/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8177 - loss: 0.4519\n",
            "Epoch 138: val_loss did not improve from 0.19765\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8168 - loss: 0.4551 - val_accuracy: 0.9585 - val_loss: 0.2182\n",
            "Epoch 139/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 0.4676\n",
            "Epoch 139: val_loss did not improve from 0.19765\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8202 - loss: 0.4667 - val_accuracy: 0.9585 - val_loss: 0.2208\n",
            "Epoch 140/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 0.3981\n",
            "Epoch 140: val_loss improved from 0.19765 to 0.19672, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8552 - loss: 0.3996 - val_accuracy: 0.9308 - val_loss: 0.1967\n",
            "Epoch 141/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8247 - loss: 0.4377\n",
            "Epoch 141: val_loss did not improve from 0.19672\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8249 - loss: 0.4370 - val_accuracy: 0.8997 - val_loss: 0.2790\n",
            "Epoch 142/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8272 - loss: 0.4187\n",
            "Epoch 142: val_loss improved from 0.19672 to 0.18345, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8273 - loss: 0.4184 - val_accuracy: 0.9343 - val_loss: 0.1835\n",
            "Epoch 143/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8313 - loss: 0.4573\n",
            "Epoch 143: val_loss did not improve from 0.18345\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8315 - loss: 0.4561 - val_accuracy: 0.9343 - val_loss: 0.2101\n",
            "Epoch 144/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8265 - loss: 0.4295\n",
            "Epoch 144: val_loss improved from 0.18345 to 0.17064, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8268 - loss: 0.4289 - val_accuracy: 0.9585 - val_loss: 0.1706\n",
            "Epoch 145/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8273 - loss: 0.4307\n",
            "Epoch 145: val_loss did not improve from 0.17064\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8289 - loss: 0.4288 - val_accuracy: 0.9446 - val_loss: 0.1724\n",
            "Epoch 146/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8412 - loss: 0.4071\n",
            "Epoch 146: val_loss did not improve from 0.17064\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8418 - loss: 0.4058 - val_accuracy: 0.9204 - val_loss: 0.2340\n",
            "Epoch 147/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8373 - loss: 0.4610\n",
            "Epoch 147: val_loss did not improve from 0.17064\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8385 - loss: 0.4558 - val_accuracy: 0.9239 - val_loss: 0.2188\n",
            "Epoch 148/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8627 - loss: 0.3737\n",
            "Epoch 148: val_loss did not improve from 0.17064\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8603 - loss: 0.3801 - val_accuracy: 0.9204 - val_loss: 0.2527\n",
            "Epoch 149/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8493 - loss: 0.4042\n",
            "Epoch 149: val_loss did not improve from 0.17064\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8500 - loss: 0.4029 - val_accuracy: 0.9446 - val_loss: 0.2063\n",
            "Epoch 150/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8508 - loss: 0.4074\n",
            "Epoch 150: val_loss did not improve from 0.17064\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8500 - loss: 0.4089 - val_accuracy: 0.9446 - val_loss: 0.1786\n",
            "Epoch 151/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8122 - loss: 0.4737\n",
            "Epoch 151: val_loss did not improve from 0.17064\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8137 - loss: 0.4712 - val_accuracy: 0.8927 - val_loss: 0.2641\n",
            "Epoch 152/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8463 - loss: 0.4209\n",
            "Epoch 152: val_loss did not improve from 0.17064\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8453 - loss: 0.4216 - val_accuracy: 0.9516 - val_loss: 0.1744\n",
            "Epoch 153/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8279 - loss: 0.4114\n",
            "Epoch 153: val_loss did not improve from 0.17064\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8277 - loss: 0.4122 - val_accuracy: 0.9619 - val_loss: 0.1711\n",
            "Epoch 154/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8521 - loss: 0.4034\n",
            "Epoch 154: val_loss did not improve from 0.17064\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8516 - loss: 0.4035 - val_accuracy: 0.9481 - val_loss: 0.1747\n",
            "Epoch 155/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8392 - loss: 0.4124\n",
            "Epoch 155: val_loss did not improve from 0.17064\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8396 - loss: 0.4120 - val_accuracy: 0.9550 - val_loss: 0.2013\n",
            "Epoch 156/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8238 - loss: 0.4312\n",
            "Epoch 156: val_loss improved from 0.17064 to 0.16005, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8242 - loss: 0.4308 - val_accuracy: 0.9412 - val_loss: 0.1600\n",
            "Epoch 157/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8343 - loss: 0.4339\n",
            "Epoch 157: val_loss did not improve from 0.16005\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8355 - loss: 0.4316 - val_accuracy: 0.9273 - val_loss: 0.2087\n",
            "Epoch 158/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8431 - loss: 0.4298\n",
            "Epoch 158: val_loss did not improve from 0.16005\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8427 - loss: 0.4290 - val_accuracy: 0.9481 - val_loss: 0.1833\n",
            "Epoch 159/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8459 - loss: 0.3835\n",
            "Epoch 159: val_loss did not improve from 0.16005\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8459 - loss: 0.3853 - val_accuracy: 0.9273 - val_loss: 0.1935\n",
            "Epoch 160/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8490 - loss: 0.3841\n",
            "Epoch 160: val_loss improved from 0.16005 to 0.14434, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8487 - loss: 0.3865 - val_accuracy: 0.9758 - val_loss: 0.1443\n",
            "Epoch 161/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8428 - loss: 0.3930\n",
            "Epoch 161: val_loss did not improve from 0.14434\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8455 - loss: 0.3898 - val_accuracy: 0.9204 - val_loss: 0.2325\n",
            "Epoch 162/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8475 - loss: 0.3811\n",
            "Epoch 162: val_loss did not improve from 0.14434\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8474 - loss: 0.3816 - val_accuracy: 0.9066 - val_loss: 0.2260\n",
            "Epoch 163/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8451 - loss: 0.3902\n",
            "Epoch 163: val_loss did not improve from 0.14434\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8458 - loss: 0.3905 - val_accuracy: 0.9758 - val_loss: 0.1481\n",
            "Epoch 164/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8702 - loss: 0.3639\n",
            "Epoch 164: val_loss did not improve from 0.14434\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8666 - loss: 0.3710 - val_accuracy: 0.8997 - val_loss: 0.2207\n",
            "Epoch 165/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 0.4054\n",
            "Epoch 165: val_loss did not improve from 0.14434\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8401 - loss: 0.4034 - val_accuracy: 0.9723 - val_loss: 0.1448\n",
            "Epoch 166/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8593 - loss: 0.3874\n",
            "Epoch 166: val_loss did not improve from 0.14434\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8561 - loss: 0.3923 - val_accuracy: 0.9343 - val_loss: 0.1832\n",
            "Epoch 167/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8477 - loss: 0.3781\n",
            "Epoch 167: val_loss did not improve from 0.14434\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8476 - loss: 0.3784 - val_accuracy: 0.9377 - val_loss: 0.1787\n",
            "Epoch 168/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8510 - loss: 0.3730\n",
            "Epoch 168: val_loss did not improve from 0.14434\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8522 - loss: 0.3715 - val_accuracy: 0.9377 - val_loss: 0.2035\n",
            "Epoch 169/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 0.4294\n",
            "Epoch 169: val_loss did not improve from 0.14434\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8401 - loss: 0.4270 - val_accuracy: 0.8893 - val_loss: 0.3081\n",
            "Epoch 170/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8448 - loss: 0.3981\n",
            "Epoch 170: val_loss improved from 0.14434 to 0.13917, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8437 - loss: 0.4002 - val_accuracy: 0.9723 - val_loss: 0.1392\n",
            "Epoch 171/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8694 - loss: 0.3424\n",
            "Epoch 171: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8686 - loss: 0.3451 - val_accuracy: 0.9550 - val_loss: 0.1623\n",
            "Epoch 172/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8644 - loss: 0.3790\n",
            "Epoch 172: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8637 - loss: 0.3801 - val_accuracy: 0.9585 - val_loss: 0.1448\n",
            "Epoch 173/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8515 - loss: 0.4166\n",
            "Epoch 173: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8501 - loss: 0.4192 - val_accuracy: 0.8927 - val_loss: 0.2801\n",
            "Epoch 174/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8332 - loss: 0.4381\n",
            "Epoch 174: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8334 - loss: 0.4388 - val_accuracy: 0.9516 - val_loss: 0.1953\n",
            "Epoch 175/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.4515\n",
            "Epoch 175: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8219 - loss: 0.4490 - val_accuracy: 0.9654 - val_loss: 0.1635\n",
            "Epoch 176/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8419 - loss: 0.3850\n",
            "Epoch 176: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8420 - loss: 0.3857 - val_accuracy: 0.9377 - val_loss: 0.1707\n",
            "Epoch 177/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8708 - loss: 0.3484\n",
            "Epoch 177: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8689 - loss: 0.3525 - val_accuracy: 0.9412 - val_loss: 0.1741\n",
            "Epoch 178/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8695 - loss: 0.3620\n",
            "Epoch 178: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8690 - loss: 0.3634 - val_accuracy: 0.9135 - val_loss: 0.2261\n",
            "Epoch 179/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8301 - loss: 0.4131\n",
            "Epoch 179: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8302 - loss: 0.4133 - val_accuracy: 0.9308 - val_loss: 0.1941\n",
            "Epoch 180/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8648 - loss: 0.3527\n",
            "Epoch 180: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8644 - loss: 0.3536 - val_accuracy: 0.9377 - val_loss: 0.2152\n",
            "Epoch 181/500\n",
            "\u001b[1m34/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8985 - loss: 0.2941\n",
            "Epoch 181: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8936 - loss: 0.3035 - val_accuracy: 0.9412 - val_loss: 0.1756\n",
            "Epoch 182/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.4925\n",
            "Epoch 182: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8113 - loss: 0.4912 - val_accuracy: 0.9550 - val_loss: 0.1707\n",
            "Epoch 183/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8579 - loss: 0.3521\n",
            "Epoch 183: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8585 - loss: 0.3528 - val_accuracy: 0.9516 - val_loss: 0.1577\n",
            "Epoch 184/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 0.3788\n",
            "Epoch 184: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8555 - loss: 0.3797 - val_accuracy: 0.9308 - val_loss: 0.1878\n",
            "Epoch 185/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8595 - loss: 0.3759\n",
            "Epoch 185: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8601 - loss: 0.3775 - val_accuracy: 0.9343 - val_loss: 0.2011\n",
            "Epoch 186/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8660 - loss: 0.3657\n",
            "Epoch 186: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8650 - loss: 0.3672 - val_accuracy: 0.9481 - val_loss: 0.1561\n",
            "Epoch 187/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8439 - loss: 0.4019\n",
            "Epoch 187: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8449 - loss: 0.3991 - val_accuracy: 0.9135 - val_loss: 0.2586\n",
            "Epoch 188/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8503 - loss: 0.4058\n",
            "Epoch 188: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8503 - loss: 0.4056 - val_accuracy: 0.9204 - val_loss: 0.2012\n",
            "Epoch 189/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8445 - loss: 0.4028\n",
            "Epoch 189: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8454 - loss: 0.4003 - val_accuracy: 0.9550 - val_loss: 0.1506\n",
            "Epoch 190/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8642 - loss: 0.3625\n",
            "Epoch 190: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8649 - loss: 0.3612 - val_accuracy: 0.9550 - val_loss: 0.1480\n",
            "Epoch 191/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8520 - loss: 0.3777\n",
            "Epoch 191: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8524 - loss: 0.3777 - val_accuracy: 0.9135 - val_loss: 0.2241\n",
            "Epoch 192/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8853 - loss: 0.3070\n",
            "Epoch 192: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8840 - loss: 0.3112 - val_accuracy: 0.9377 - val_loss: 0.2024\n",
            "Epoch 193/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8469 - loss: 0.4175\n",
            "Epoch 193: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8490 - loss: 0.4114 - val_accuracy: 0.9585 - val_loss: 0.1569\n",
            "Epoch 194/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.3954\n",
            "Epoch 194: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8552 - loss: 0.3951 - val_accuracy: 0.9516 - val_loss: 0.1674\n",
            "Epoch 195/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.3023\n",
            "Epoch 195: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8891 - loss: 0.3041 - val_accuracy: 0.9204 - val_loss: 0.2227\n",
            "Epoch 196/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8562 - loss: 0.3552\n",
            "Epoch 196: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8562 - loss: 0.3606 - val_accuracy: 0.9550 - val_loss: 0.1563\n",
            "Epoch 197/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8626 - loss: 0.3527\n",
            "Epoch 197: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8626 - loss: 0.3524 - val_accuracy: 0.9377 - val_loss: 0.1625\n",
            "Epoch 198/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8569 - loss: 0.3875\n",
            "Epoch 198: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8577 - loss: 0.3852 - val_accuracy: 0.9239 - val_loss: 0.2318\n",
            "Epoch 199/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8627 - loss: 0.3715\n",
            "Epoch 199: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8610 - loss: 0.3734 - val_accuracy: 0.9170 - val_loss: 0.1998\n",
            "Epoch 200/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8412 - loss: 0.4400\n",
            "Epoch 200: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8419 - loss: 0.4366 - val_accuracy: 0.9412 - val_loss: 0.1846\n",
            "Epoch 201/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8711 - loss: 0.3635\n",
            "Epoch 201: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8688 - loss: 0.3664 - val_accuracy: 0.9170 - val_loss: 0.2128\n",
            "Epoch 202/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8491 - loss: 0.3588\n",
            "Epoch 202: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8493 - loss: 0.3589 - val_accuracy: 0.9412 - val_loss: 0.1774\n",
            "Epoch 203/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8037 - loss: 0.4942 \n",
            "Epoch 203: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8040 - loss: 0.4932 - val_accuracy: 0.9170 - val_loss: 0.2139\n",
            "Epoch 204/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8528 - loss: 0.3894\n",
            "Epoch 204: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8524 - loss: 0.3899 - val_accuracy: 0.9273 - val_loss: 0.1858\n",
            "Epoch 205/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.3945\n",
            "Epoch 205: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8494 - loss: 0.3900 - val_accuracy: 0.9654 - val_loss: 0.1441\n",
            "Epoch 206/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8403 - loss: 0.4231\n",
            "Epoch 206: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8421 - loss: 0.4174 - val_accuracy: 0.9446 - val_loss: 0.1607\n",
            "Epoch 207/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8335 - loss: 0.4534\n",
            "Epoch 207: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8350 - loss: 0.4473 - val_accuracy: 0.8858 - val_loss: 0.2851\n",
            "Epoch 208/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8362 - loss: 0.4292\n",
            "Epoch 208: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8364 - loss: 0.4318 - val_accuracy: 0.9031 - val_loss: 0.2124\n",
            "Epoch 209/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 0.3792\n",
            "Epoch 209: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8406 - loss: 0.3807 - val_accuracy: 0.9273 - val_loss: 0.1969\n",
            "Epoch 210/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 0.3841\n",
            "Epoch 210: val_loss did not improve from 0.13917\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8564 - loss: 0.3846 - val_accuracy: 0.9619 - val_loss: 0.1491\n",
            "Epoch 211/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8565 - loss: 0.3585\n",
            "Epoch 211: val_loss improved from 0.13917 to 0.12789, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8567 - loss: 0.3589 - val_accuracy: 0.9758 - val_loss: 0.1279\n",
            "Epoch 212/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8542 - loss: 0.4022\n",
            "Epoch 212: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8543 - loss: 0.3996 - val_accuracy: 0.9619 - val_loss: 0.1443\n",
            "Epoch 213/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8364 - loss: 0.4190\n",
            "Epoch 213: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8386 - loss: 0.4135 - val_accuracy: 0.9412 - val_loss: 0.1486\n",
            "Epoch 214/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8264 - loss: 0.4562\n",
            "Epoch 214: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8280 - loss: 0.4508 - val_accuracy: 0.9273 - val_loss: 0.1845\n",
            "Epoch 215/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8655 - loss: 0.3450\n",
            "Epoch 215: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8661 - loss: 0.3447 - val_accuracy: 0.9446 - val_loss: 0.1661\n",
            "Epoch 216/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8885 - loss: 0.2981\n",
            "Epoch 216: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8847 - loss: 0.3070 - val_accuracy: 0.9550 - val_loss: 0.1350\n",
            "Epoch 217/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8540 - loss: 0.3657\n",
            "Epoch 217: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8541 - loss: 0.3654 - val_accuracy: 0.9585 - val_loss: 0.1492\n",
            "Epoch 218/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8655 - loss: 0.3441\n",
            "Epoch 218: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8646 - loss: 0.3478 - val_accuracy: 0.9481 - val_loss: 0.1444\n",
            "Epoch 219/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8581 - loss: 0.3968\n",
            "Epoch 219: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8588 - loss: 0.3949 - val_accuracy: 0.9550 - val_loss: 0.1358\n",
            "Epoch 220/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8721 - loss: 0.3779\n",
            "Epoch 220: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8708 - loss: 0.3781 - val_accuracy: 0.9377 - val_loss: 0.1536\n",
            "Epoch 221/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8712 - loss: 0.3851\n",
            "Epoch 221: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8703 - loss: 0.3829 - val_accuracy: 0.8962 - val_loss: 0.2693\n",
            "Epoch 222/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.3260\n",
            "Epoch 222: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8834 - loss: 0.3255 - val_accuracy: 0.9204 - val_loss: 0.2066\n",
            "Epoch 223/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7958 - loss: 0.5667\n",
            "Epoch 223: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7964 - loss: 0.5619 - val_accuracy: 0.8997 - val_loss: 0.2639\n",
            "Epoch 224/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8317 - loss: 0.4257\n",
            "Epoch 224: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8332 - loss: 0.4232 - val_accuracy: 0.9446 - val_loss: 0.1854\n",
            "Epoch 225/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8374 - loss: 0.4110\n",
            "Epoch 225: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8368 - loss: 0.4111 - val_accuracy: 0.9585 - val_loss: 0.1680\n",
            "Epoch 226/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8562 - loss: 0.3537\n",
            "Epoch 226: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8564 - loss: 0.3567 - val_accuracy: 0.9550 - val_loss: 0.1583\n",
            "Epoch 227/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8753 - loss: 0.3575\n",
            "Epoch 227: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8753 - loss: 0.3575 - val_accuracy: 0.9516 - val_loss: 0.1489\n",
            "Epoch 228/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8715 - loss: 0.3363\n",
            "Epoch 228: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8713 - loss: 0.3365 - val_accuracy: 0.9481 - val_loss: 0.1453\n",
            "Epoch 229/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.3115\n",
            "Epoch 229: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8893 - loss: 0.3129 - val_accuracy: 0.9585 - val_loss: 0.1333\n",
            "Epoch 230/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8806 - loss: 0.3538\n",
            "Epoch 230: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8811 - loss: 0.3501 - val_accuracy: 0.9031 - val_loss: 0.1982\n",
            "Epoch 231/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8629 - loss: 0.3331\n",
            "Epoch 231: val_loss did not improve from 0.12789\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8620 - loss: 0.3391 - val_accuracy: 0.9481 - val_loss: 0.1702\n",
            "Epoch 232/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.2853\n",
            "Epoch 232: val_loss improved from 0.12789 to 0.10380, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9030 - loss: 0.2866 - val_accuracy: 0.9723 - val_loss: 0.1038\n",
            "Epoch 233/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9001 - loss: 0.3144\n",
            "Epoch 233: val_loss improved from 0.10380 to 0.09339, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8998 - loss: 0.3144 - val_accuracy: 0.9827 - val_loss: 0.0934\n",
            "Epoch 234/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8718 - loss: 0.3132\n",
            "Epoch 234: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8725 - loss: 0.3150 - val_accuracy: 0.9135 - val_loss: 0.2292\n",
            "Epoch 235/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9078 - loss: 0.3099\n",
            "Epoch 235: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9070 - loss: 0.3096 - val_accuracy: 0.9516 - val_loss: 0.1518\n",
            "Epoch 236/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8554 - loss: 0.4185\n",
            "Epoch 236: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8565 - loss: 0.4153 - val_accuracy: 0.9516 - val_loss: 0.1352\n",
            "Epoch 237/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8505 - loss: 0.3774\n",
            "Epoch 237: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8528 - loss: 0.3729 - val_accuracy: 0.9481 - val_loss: 0.1420\n",
            "Epoch 238/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8899 - loss: 0.3051\n",
            "Epoch 238: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8881 - loss: 0.3083 - val_accuracy: 0.9827 - val_loss: 0.1069\n",
            "Epoch 239/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8984 - loss: 0.2997\n",
            "Epoch 239: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8964 - loss: 0.3043 - val_accuracy: 0.9585 - val_loss: 0.1201\n",
            "Epoch 240/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8808 - loss: 0.3155\n",
            "Epoch 240: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8811 - loss: 0.3164 - val_accuracy: 0.9689 - val_loss: 0.1023\n",
            "Epoch 241/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8972 - loss: 0.3172\n",
            "Epoch 241: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8967 - loss: 0.3171 - val_accuracy: 0.9377 - val_loss: 0.1623\n",
            "Epoch 242/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8833 - loss: 0.3371\n",
            "Epoch 242: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8839 - loss: 0.3360 - val_accuracy: 0.9654 - val_loss: 0.1132\n",
            "Epoch 243/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9146 - loss: 0.2803\n",
            "Epoch 243: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9105 - loss: 0.2858 - val_accuracy: 0.9896 - val_loss: 0.0986\n",
            "Epoch 244/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8959 - loss: 0.2758\n",
            "Epoch 244: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8969 - loss: 0.2747 - val_accuracy: 0.9550 - val_loss: 0.1233\n",
            "Epoch 245/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8877 - loss: 0.3186\n",
            "Epoch 245: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8879 - loss: 0.3181 - val_accuracy: 0.9758 - val_loss: 0.1027\n",
            "Epoch 246/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8901 - loss: 0.3260\n",
            "Epoch 246: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8903 - loss: 0.3260 - val_accuracy: 0.9654 - val_loss: 0.1072\n",
            "Epoch 247/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8870 - loss: 0.2995\n",
            "Epoch 247: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8868 - loss: 0.3011 - val_accuracy: 0.9758 - val_loss: 0.1009\n",
            "Epoch 248/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8848 - loss: 0.2969\n",
            "Epoch 248: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8839 - loss: 0.2992 - val_accuracy: 0.9516 - val_loss: 0.1108\n",
            "Epoch 249/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8895 - loss: 0.3244\n",
            "Epoch 249: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8886 - loss: 0.3241 - val_accuracy: 0.9481 - val_loss: 0.1243\n",
            "Epoch 250/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9025 - loss: 0.2868\n",
            "Epoch 250: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9016 - loss: 0.2894 - val_accuracy: 0.9723 - val_loss: 0.1140\n",
            "Epoch 251/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8959 - loss: 0.3137\n",
            "Epoch 251: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8959 - loss: 0.3134 - val_accuracy: 0.9550 - val_loss: 0.1267\n",
            "Epoch 252/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8352 - loss: 0.4523\n",
            "Epoch 252: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8365 - loss: 0.4498 - val_accuracy: 0.8616 - val_loss: 0.3767\n",
            "Epoch 253/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8813 - loss: 0.3466\n",
            "Epoch 253: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8806 - loss: 0.3467 - val_accuracy: 0.8997 - val_loss: 0.2428\n",
            "Epoch 254/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8925 - loss: 0.2890\n",
            "Epoch 254: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8900 - loss: 0.2978 - val_accuracy: 0.9619 - val_loss: 0.1115\n",
            "Epoch 255/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8816 - loss: 0.3361\n",
            "Epoch 255: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8818 - loss: 0.3372 - val_accuracy: 0.9550 - val_loss: 0.1074\n",
            "Epoch 256/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8890 - loss: 0.3228\n",
            "Epoch 256: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8865 - loss: 0.3289 - val_accuracy: 0.9585 - val_loss: 0.1276\n",
            "Epoch 257/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9063 - loss: 0.2655\n",
            "Epoch 257: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9053 - loss: 0.2679 - val_accuracy: 0.9446 - val_loss: 0.1475\n",
            "Epoch 258/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8605 - loss: 0.3594\n",
            "Epoch 258: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8604 - loss: 0.3590 - val_accuracy: 0.9481 - val_loss: 0.1284\n",
            "Epoch 259/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8885 - loss: 0.3059\n",
            "Epoch 259: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8886 - loss: 0.3051 - val_accuracy: 0.9619 - val_loss: 0.1001\n",
            "Epoch 260/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9020 - loss: 0.3046\n",
            "Epoch 260: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8998 - loss: 0.3075 - val_accuracy: 0.9689 - val_loss: 0.1169\n",
            "Epoch 261/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8925 - loss: 0.2873\n",
            "Epoch 261: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8933 - loss: 0.2878 - val_accuracy: 0.9585 - val_loss: 0.1130\n",
            "Epoch 262/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8943 - loss: 0.2968\n",
            "Epoch 262: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8925 - loss: 0.3005 - val_accuracy: 0.9343 - val_loss: 0.1382\n",
            "Epoch 263/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8961 - loss: 0.3101\n",
            "Epoch 263: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8954 - loss: 0.3121 - val_accuracy: 0.9619 - val_loss: 0.1244\n",
            "Epoch 264/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9068 - loss: 0.2842\n",
            "Epoch 264: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9055 - loss: 0.2892 - val_accuracy: 0.9723 - val_loss: 0.0960\n",
            "Epoch 265/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8958 - loss: 0.3436\n",
            "Epoch 265: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8956 - loss: 0.3420 - val_accuracy: 0.9481 - val_loss: 0.1162\n",
            "Epoch 266/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8903 - loss: 0.3009\n",
            "Epoch 266: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8901 - loss: 0.3017 - val_accuracy: 0.9516 - val_loss: 0.1232\n",
            "Epoch 267/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8926 - loss: 0.3115\n",
            "Epoch 267: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8912 - loss: 0.3151 - val_accuracy: 0.9689 - val_loss: 0.1030\n",
            "Epoch 268/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8579 - loss: 0.4505\n",
            "Epoch 268: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8623 - loss: 0.4345 - val_accuracy: 0.9446 - val_loss: 0.1286\n",
            "Epoch 269/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8578 - loss: 0.4281\n",
            "Epoch 269: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8575 - loss: 0.4236 - val_accuracy: 0.9273 - val_loss: 0.1939\n",
            "Epoch 270/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8873 - loss: 0.3101\n",
            "Epoch 270: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8871 - loss: 0.3111 - val_accuracy: 0.9343 - val_loss: 0.1501\n",
            "Epoch 271/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9051 - loss: 0.2559\n",
            "Epoch 271: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9049 - loss: 0.2562 - val_accuracy: 0.9654 - val_loss: 0.1085\n",
            "Epoch 272/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8885 - loss: 0.2979\n",
            "Epoch 272: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8886 - loss: 0.2984 - val_accuracy: 0.9412 - val_loss: 0.1517\n",
            "Epoch 273/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9151 - loss: 0.2633\n",
            "Epoch 273: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9145 - loss: 0.2649 - val_accuracy: 0.9654 - val_loss: 0.1034\n",
            "Epoch 274/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9132 - loss: 0.2628\n",
            "Epoch 274: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9130 - loss: 0.2626 - val_accuracy: 0.9654 - val_loss: 0.0984\n",
            "Epoch 275/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8828 - loss: 0.3133\n",
            "Epoch 275: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8842 - loss: 0.3109 - val_accuracy: 0.9550 - val_loss: 0.1166\n",
            "Epoch 276/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8962 - loss: 0.3180\n",
            "Epoch 276: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8970 - loss: 0.3181 - val_accuracy: 0.9758 - val_loss: 0.0969\n",
            "Epoch 277/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8852 - loss: 0.3089\n",
            "Epoch 277: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8859 - loss: 0.3076 - val_accuracy: 0.9446 - val_loss: 0.1914\n",
            "Epoch 278/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8977 - loss: 0.3246\n",
            "Epoch 278: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8987 - loss: 0.3213 - val_accuracy: 0.9723 - val_loss: 0.0994\n",
            "Epoch 279/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2656\n",
            "Epoch 279: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9116 - loss: 0.2621 - val_accuracy: 0.9446 - val_loss: 0.1421\n",
            "Epoch 280/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8957 - loss: 0.3061\n",
            "Epoch 280: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8959 - loss: 0.3058 - val_accuracy: 0.9412 - val_loss: 0.1416\n",
            "Epoch 281/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8980 - loss: 0.2747\n",
            "Epoch 281: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8974 - loss: 0.2782 - val_accuracy: 0.9481 - val_loss: 0.1663\n",
            "Epoch 282/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8862 - loss: 0.3288\n",
            "Epoch 282: val_loss did not improve from 0.09339\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8879 - loss: 0.3262 - val_accuracy: 0.9308 - val_loss: 0.1779\n",
            "Epoch 283/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9040 - loss: 0.2681\n",
            "Epoch 283: val_loss improved from 0.09339 to 0.08658, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9040 - loss: 0.2683 - val_accuracy: 0.9758 - val_loss: 0.0866\n",
            "Epoch 284/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9077 - loss: 0.2690\n",
            "Epoch 284: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9070 - loss: 0.2712 - val_accuracy: 0.9654 - val_loss: 0.1130\n",
            "Epoch 285/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9083 - loss: 0.2855\n",
            "Epoch 285: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9074 - loss: 0.2869 - val_accuracy: 0.9585 - val_loss: 0.1208\n",
            "Epoch 286/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8780 - loss: 0.3402\n",
            "Epoch 286: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8791 - loss: 0.3393 - val_accuracy: 0.9308 - val_loss: 0.1439\n",
            "Epoch 287/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9145 - loss: 0.2801\n",
            "Epoch 287: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9133 - loss: 0.2810 - val_accuracy: 0.9619 - val_loss: 0.1176\n",
            "Epoch 288/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9104 - loss: 0.2860\n",
            "Epoch 288: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9099 - loss: 0.2860 - val_accuracy: 0.9273 - val_loss: 0.2148\n",
            "Epoch 289/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8833 - loss: 0.3203\n",
            "Epoch 289: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8841 - loss: 0.3184 - val_accuracy: 0.9550 - val_loss: 0.1098\n",
            "Epoch 290/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9140 - loss: 0.2536\n",
            "Epoch 290: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9122 - loss: 0.2599 - val_accuracy: 0.9550 - val_loss: 0.1122\n",
            "Epoch 291/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9005 - loss: 0.3000\n",
            "Epoch 291: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8984 - loss: 0.3041 - val_accuracy: 0.9343 - val_loss: 0.1243\n",
            "Epoch 292/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9109 - loss: 0.2478\n",
            "Epoch 292: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9107 - loss: 0.2480 - val_accuracy: 0.9516 - val_loss: 0.0938\n",
            "Epoch 293/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8986 - loss: 0.3115\n",
            "Epoch 293: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8977 - loss: 0.3138 - val_accuracy: 0.9689 - val_loss: 0.1064\n",
            "Epoch 294/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8931 - loss: 0.2781\n",
            "Epoch 294: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8938 - loss: 0.2786 - val_accuracy: 0.9446 - val_loss: 0.1203\n",
            "Epoch 295/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9195 - loss: 0.2546\n",
            "Epoch 295: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9177 - loss: 0.2585 - val_accuracy: 0.9723 - val_loss: 0.0954\n",
            "Epoch 296/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9201 - loss: 0.2379\n",
            "Epoch 296: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9195 - loss: 0.2391 - val_accuracy: 0.9308 - val_loss: 0.1489\n",
            "Epoch 297/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8947 - loss: 0.2877\n",
            "Epoch 297: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8975 - loss: 0.2826 - val_accuracy: 0.9585 - val_loss: 0.0936\n",
            "Epoch 298/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9152 - loss: 0.2526\n",
            "Epoch 298: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9143 - loss: 0.2568 - val_accuracy: 0.9481 - val_loss: 0.1158\n",
            "Epoch 299/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8980 - loss: 0.3140\n",
            "Epoch 299: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8984 - loss: 0.3113 - val_accuracy: 0.9654 - val_loss: 0.0922\n",
            "Epoch 300/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9215 - loss: 0.2296\n",
            "Epoch 300: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9205 - loss: 0.2322 - val_accuracy: 0.9412 - val_loss: 0.1723\n",
            "Epoch 301/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9073 - loss: 0.2808\n",
            "Epoch 301: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9068 - loss: 0.2807 - val_accuracy: 0.9343 - val_loss: 0.2040\n",
            "Epoch 302/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8920 - loss: 0.3162\n",
            "Epoch 302: val_loss did not improve from 0.08658\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8929 - loss: 0.3142 - val_accuracy: 0.9412 - val_loss: 0.1141\n",
            "Epoch 303/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9030 - loss: 0.2896\n",
            "Epoch 303: val_loss improved from 0.08658 to 0.08054, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9029 - loss: 0.2913 - val_accuracy: 0.9723 - val_loss: 0.0805\n",
            "Epoch 304/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.2805\n",
            "Epoch 304: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8961 - loss: 0.2795 - val_accuracy: 0.9585 - val_loss: 0.0939\n",
            "Epoch 305/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9183 - loss: 0.2587\n",
            "Epoch 305: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9173 - loss: 0.2593 - val_accuracy: 0.9481 - val_loss: 0.1119\n",
            "Epoch 306/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8991 - loss: 0.2754\n",
            "Epoch 306: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8974 - loss: 0.2815 - val_accuracy: 0.9689 - val_loss: 0.0936\n",
            "Epoch 307/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8724 - loss: 0.3658\n",
            "Epoch 307: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8701 - loss: 0.3677 - val_accuracy: 0.9343 - val_loss: 0.1629\n",
            "Epoch 308/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8863 - loss: 0.3057\n",
            "Epoch 308: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8867 - loss: 0.3058 - val_accuracy: 0.9689 - val_loss: 0.1068\n",
            "Epoch 309/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8888 - loss: 0.3356\n",
            "Epoch 309: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8887 - loss: 0.3358 - val_accuracy: 0.9481 - val_loss: 0.1300\n",
            "Epoch 310/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8864 - loss: 0.3180\n",
            "Epoch 310: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8862 - loss: 0.3168 - val_accuracy: 0.9758 - val_loss: 0.0915\n",
            "Epoch 311/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9055 - loss: 0.2774\n",
            "Epoch 311: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9056 - loss: 0.2777 - val_accuracy: 0.9239 - val_loss: 0.2259\n",
            "Epoch 312/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8436 - loss: 0.4902\n",
            "Epoch 312: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8409 - loss: 0.4940 - val_accuracy: 0.8547 - val_loss: 0.3187\n",
            "Epoch 313/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8606 - loss: 0.3582\n",
            "Epoch 313: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8599 - loss: 0.3615 - val_accuracy: 0.9239 - val_loss: 0.1671\n",
            "Epoch 314/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8824 - loss: 0.3240\n",
            "Epoch 314: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8828 - loss: 0.3221 - val_accuracy: 0.9619 - val_loss: 0.1109\n",
            "Epoch 315/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9049 - loss: 0.2928\n",
            "Epoch 315: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9036 - loss: 0.2948 - val_accuracy: 0.9723 - val_loss: 0.0939\n",
            "Epoch 316/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8884 - loss: 0.2781\n",
            "Epoch 316: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8907 - loss: 0.2754 - val_accuracy: 0.9516 - val_loss: 0.1159\n",
            "Epoch 317/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8867 - loss: 0.3111\n",
            "Epoch 317: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8868 - loss: 0.3108 - val_accuracy: 0.9689 - val_loss: 0.1027\n",
            "Epoch 318/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2719\n",
            "Epoch 318: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9091 - loss: 0.2742 - val_accuracy: 0.9516 - val_loss: 0.1160\n",
            "Epoch 319/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2618\n",
            "Epoch 319: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8999 - loss: 0.2617 - val_accuracy: 0.9689 - val_loss: 0.1044\n",
            "Epoch 320/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9074 - loss: 0.2363\n",
            "Epoch 320: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9077 - loss: 0.2364 - val_accuracy: 0.9619 - val_loss: 0.0927\n",
            "Epoch 321/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9150 - loss: 0.2531 \n",
            "Epoch 321: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9142 - loss: 0.2549 - val_accuracy: 0.9758 - val_loss: 0.0910\n",
            "Epoch 322/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8917 - loss: 0.3291\n",
            "Epoch 322: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8915 - loss: 0.3293 - val_accuracy: 0.9516 - val_loss: 0.1079\n",
            "Epoch 323/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9105 - loss: 0.2543\n",
            "Epoch 323: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9106 - loss: 0.2546 - val_accuracy: 0.9723 - val_loss: 0.0945\n",
            "Epoch 324/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8993 - loss: 0.3122\n",
            "Epoch 324: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9016 - loss: 0.3046 - val_accuracy: 0.9481 - val_loss: 0.1027\n",
            "Epoch 325/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9027 - loss: 0.2679\n",
            "Epoch 325: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9030 - loss: 0.2695 - val_accuracy: 0.9585 - val_loss: 0.0978\n",
            "Epoch 326/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9038 - loss: 0.2910\n",
            "Epoch 326: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9048 - loss: 0.2881 - val_accuracy: 0.9723 - val_loss: 0.1000\n",
            "Epoch 327/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9153 - loss: 0.2422\n",
            "Epoch 327: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9145 - loss: 0.2448 - val_accuracy: 0.9758 - val_loss: 0.0950\n",
            "Epoch 328/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8919 - loss: 0.2962\n",
            "Epoch 328: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8929 - loss: 0.2945 - val_accuracy: 0.9446 - val_loss: 0.1250\n",
            "Epoch 329/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2843\n",
            "Epoch 329: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9169 - loss: 0.2809 - val_accuracy: 0.9619 - val_loss: 0.0896\n",
            "Epoch 330/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9028 - loss: 0.2987\n",
            "Epoch 330: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9016 - loss: 0.2980 - val_accuracy: 0.9723 - val_loss: 0.0875\n",
            "Epoch 331/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8988 - loss: 0.2523\n",
            "Epoch 331: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8988 - loss: 0.2527 - val_accuracy: 0.9481 - val_loss: 0.1324\n",
            "Epoch 332/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8830 - loss: 0.2850\n",
            "Epoch 332: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8849 - loss: 0.2827 - val_accuracy: 0.9654 - val_loss: 0.0838\n",
            "Epoch 333/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9169 - loss: 0.2841\n",
            "Epoch 333: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9140 - loss: 0.2879 - val_accuracy: 0.9689 - val_loss: 0.0825\n",
            "Epoch 334/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9016 - loss: 0.2994\n",
            "Epoch 334: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9016 - loss: 0.2969 - val_accuracy: 0.9689 - val_loss: 0.1099\n",
            "Epoch 335/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9074 - loss: 0.2481\n",
            "Epoch 335: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9071 - loss: 0.2514 - val_accuracy: 0.9550 - val_loss: 0.1350\n",
            "Epoch 336/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9078 - loss: 0.2867\n",
            "Epoch 336: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9079 - loss: 0.2863 - val_accuracy: 0.9481 - val_loss: 0.1169\n",
            "Epoch 337/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9201 - loss: 0.2552\n",
            "Epoch 337: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9196 - loss: 0.2548 - val_accuracy: 0.9516 - val_loss: 0.0945\n",
            "Epoch 338/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2427\n",
            "Epoch 338: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9118 - loss: 0.2411 - val_accuracy: 0.9689 - val_loss: 0.0889\n",
            "Epoch 339/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9190 - loss: 0.2428\n",
            "Epoch 339: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9187 - loss: 0.2434 - val_accuracy: 0.9585 - val_loss: 0.1029\n",
            "Epoch 340/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9104 - loss: 0.2767\n",
            "Epoch 340: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9104 - loss: 0.2761 - val_accuracy: 0.9481 - val_loss: 0.1349\n",
            "Epoch 341/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9072 - loss: 0.2778\n",
            "Epoch 341: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9069 - loss: 0.2782 - val_accuracy: 0.9446 - val_loss: 0.1182\n",
            "Epoch 342/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9019 - loss: 0.2925\n",
            "Epoch 342: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9006 - loss: 0.2952 - val_accuracy: 0.9585 - val_loss: 0.0953\n",
            "Epoch 343/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8958 - loss: 0.2907\n",
            "Epoch 343: val_loss did not improve from 0.08054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8968 - loss: 0.2884 - val_accuracy: 0.9585 - val_loss: 0.1033\n",
            "Epoch 344/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9225 - loss: 0.2240\n",
            "Epoch 344: val_loss improved from 0.08054 to 0.07898, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9224 - loss: 0.2247 - val_accuracy: 0.9654 - val_loss: 0.0790\n",
            "Epoch 345/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.2290\n",
            "Epoch 345: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9259 - loss: 0.2275 - val_accuracy: 0.9723 - val_loss: 0.0986\n",
            "Epoch 346/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.2496\n",
            "Epoch 346: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9142 - loss: 0.2509 - val_accuracy: 0.9585 - val_loss: 0.0894\n",
            "Epoch 347/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9342 - loss: 0.2348\n",
            "Epoch 347: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9340 - loss: 0.2338 - val_accuracy: 0.9619 - val_loss: 0.0973\n",
            "Epoch 348/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8982 - loss: 0.3090\n",
            "Epoch 348: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8971 - loss: 0.3101 - val_accuracy: 0.9516 - val_loss: 0.1478\n",
            "Epoch 349/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9094 - loss: 0.2506\n",
            "Epoch 349: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9079 - loss: 0.2535 - val_accuracy: 0.9550 - val_loss: 0.1472\n",
            "Epoch 350/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9069 - loss: 0.2711\n",
            "Epoch 350: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9070 - loss: 0.2715 - val_accuracy: 0.9516 - val_loss: 0.1271\n",
            "Epoch 351/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9389 - loss: 0.1940\n",
            "Epoch 351: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9375 - loss: 0.1990 - val_accuracy: 0.9516 - val_loss: 0.1400\n",
            "Epoch 352/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8989 - loss: 0.2900\n",
            "Epoch 352: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8978 - loss: 0.2911 - val_accuracy: 0.9412 - val_loss: 0.1496\n",
            "Epoch 353/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8945 - loss: 0.3200\n",
            "Epoch 353: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8940 - loss: 0.3208 - val_accuracy: 0.9723 - val_loss: 0.0983\n",
            "Epoch 354/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9076 - loss: 0.2663\n",
            "Epoch 354: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9075 - loss: 0.2669 - val_accuracy: 0.9481 - val_loss: 0.1225\n",
            "Epoch 355/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9214 - loss: 0.2302\n",
            "Epoch 355: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9186 - loss: 0.2370 - val_accuracy: 0.9619 - val_loss: 0.0978\n",
            "Epoch 356/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8997 - loss: 0.2685\n",
            "Epoch 356: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9002 - loss: 0.2688 - val_accuracy: 0.9585 - val_loss: 0.1094\n",
            "Epoch 357/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2986\n",
            "Epoch 357: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9107 - loss: 0.2952 - val_accuracy: 0.9516 - val_loss: 0.1255\n",
            "Epoch 358/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9106 - loss: 0.2576\n",
            "Epoch 358: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9090 - loss: 0.2609 - val_accuracy: 0.9446 - val_loss: 0.1407\n",
            "Epoch 359/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9122 - loss: 0.2718\n",
            "Epoch 359: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9116 - loss: 0.2734 - val_accuracy: 0.9585 - val_loss: 0.1233\n",
            "Epoch 360/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.2966\n",
            "Epoch 360: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9040 - loss: 0.2888 - val_accuracy: 0.9550 - val_loss: 0.1101\n",
            "Epoch 361/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9281 - loss: 0.2198\n",
            "Epoch 361: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9259 - loss: 0.2255 - val_accuracy: 0.9619 - val_loss: 0.0892\n",
            "Epoch 362/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9015 - loss: 0.2589\n",
            "Epoch 362: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9016 - loss: 0.2590 - val_accuracy: 0.9481 - val_loss: 0.1212\n",
            "Epoch 363/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9112 - loss: 0.2690\n",
            "Epoch 363: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9113 - loss: 0.2679 - val_accuracy: 0.9723 - val_loss: 0.0820\n",
            "Epoch 364/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9051 - loss: 0.2691\n",
            "Epoch 364: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9047 - loss: 0.2704 - val_accuracy: 0.9619 - val_loss: 0.1073\n",
            "Epoch 365/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9252 - loss: 0.2338\n",
            "Epoch 365: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9238 - loss: 0.2363 - val_accuracy: 0.9723 - val_loss: 0.0946\n",
            "Epoch 366/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9084 - loss: 0.2813\n",
            "Epoch 366: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9105 - loss: 0.2767 - val_accuracy: 0.9723 - val_loss: 0.0902\n",
            "Epoch 367/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9124 - loss: 0.2317\n",
            "Epoch 367: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9126 - loss: 0.2324 - val_accuracy: 0.9343 - val_loss: 0.1458\n",
            "Epoch 368/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9051 - loss: 0.2614\n",
            "Epoch 368: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9052 - loss: 0.2613 - val_accuracy: 0.9585 - val_loss: 0.0946\n",
            "Epoch 369/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9050 - loss: 0.2524\n",
            "Epoch 369: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9050 - loss: 0.2525 - val_accuracy: 0.9550 - val_loss: 0.1117\n",
            "Epoch 370/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9059 - loss: 0.2923\n",
            "Epoch 370: val_loss did not improve from 0.07898\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9071 - loss: 0.2877 - val_accuracy: 0.9792 - val_loss: 0.0809\n",
            "Epoch 371/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2509\n",
            "Epoch 371: val_loss improved from 0.07898 to 0.07277, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9109 - loss: 0.2523 - val_accuracy: 0.9792 - val_loss: 0.0728\n",
            "Epoch 372/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9212 - loss: 0.2330\n",
            "Epoch 372: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9215 - loss: 0.2327 - val_accuracy: 0.9654 - val_loss: 0.0849\n",
            "Epoch 373/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9224 - loss: 0.2562\n",
            "Epoch 373: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9217 - loss: 0.2582 - val_accuracy: 0.9689 - val_loss: 0.0794\n",
            "Epoch 374/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9246 - loss: 0.2290\n",
            "Epoch 374: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9241 - loss: 0.2303 - val_accuracy: 0.9516 - val_loss: 0.1032\n",
            "Epoch 375/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2442\n",
            "Epoch 375: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9162 - loss: 0.2442 - val_accuracy: 0.9343 - val_loss: 0.1254\n",
            "Epoch 376/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9024 - loss: 0.2904\n",
            "Epoch 376: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9012 - loss: 0.2930 - val_accuracy: 0.9412 - val_loss: 0.1442\n",
            "Epoch 377/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9122 - loss: 0.2475\n",
            "Epoch 377: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9116 - loss: 0.2497 - val_accuracy: 0.9792 - val_loss: 0.0858\n",
            "Epoch 378/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8996 - loss: 0.2521\n",
            "Epoch 378: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.2533 - val_accuracy: 0.9619 - val_loss: 0.0972\n",
            "Epoch 379/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8989 - loss: 0.2922\n",
            "Epoch 379: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8999 - loss: 0.2890 - val_accuracy: 0.9550 - val_loss: 0.0879\n",
            "Epoch 380/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8949 - loss: 0.2710\n",
            "Epoch 380: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8957 - loss: 0.2738 - val_accuracy: 0.9758 - val_loss: 0.0919\n",
            "Epoch 381/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.2870\n",
            "Epoch 381: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8934 - loss: 0.2854 - val_accuracy: 0.9723 - val_loss: 0.1007\n",
            "Epoch 382/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8984 - loss: 0.2947\n",
            "Epoch 382: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8997 - loss: 0.2924 - val_accuracy: 0.9654 - val_loss: 0.1003\n",
            "Epoch 383/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8905 - loss: 0.3158\n",
            "Epoch 383: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8896 - loss: 0.3145 - val_accuracy: 0.9446 - val_loss: 0.1433\n",
            "Epoch 384/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9030 - loss: 0.2623\n",
            "Epoch 384: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9050 - loss: 0.2599 - val_accuracy: 0.9758 - val_loss: 0.0846\n",
            "Epoch 385/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9022 - loss: 0.2653\n",
            "Epoch 385: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9031 - loss: 0.2657 - val_accuracy: 0.9619 - val_loss: 0.0970\n",
            "Epoch 386/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9103 - loss: 0.2541\n",
            "Epoch 386: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9102 - loss: 0.2542 - val_accuracy: 0.9689 - val_loss: 0.0843\n",
            "Epoch 387/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8970 - loss: 0.2878\n",
            "Epoch 387: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8960 - loss: 0.2914 - val_accuracy: 0.9585 - val_loss: 0.1073\n",
            "Epoch 388/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9182 - loss: 0.2304\n",
            "Epoch 388: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9169 - loss: 0.2344 - val_accuracy: 0.9446 - val_loss: 0.1202\n",
            "Epoch 389/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8573 - loss: 0.3790\n",
            "Epoch 389: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8579 - loss: 0.3775 - val_accuracy: 0.8927 - val_loss: 0.2082\n",
            "Epoch 390/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8788 - loss: 0.3209\n",
            "Epoch 390: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8792 - loss: 0.3203 - val_accuracy: 0.9412 - val_loss: 0.1506\n",
            "Epoch 391/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8637 - loss: 0.3766\n",
            "Epoch 391: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8662 - loss: 0.3720 - val_accuracy: 0.9723 - val_loss: 0.0998\n",
            "Epoch 392/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9083 - loss: 0.2780\n",
            "Epoch 392: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9070 - loss: 0.2773 - val_accuracy: 0.9827 - val_loss: 0.0802\n",
            "Epoch 393/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9083 - loss: 0.2755\n",
            "Epoch 393: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9090 - loss: 0.2765 - val_accuracy: 0.9619 - val_loss: 0.1038\n",
            "Epoch 394/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9192 - loss: 0.2533\n",
            "Epoch 394: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9168 - loss: 0.2568 - val_accuracy: 0.9619 - val_loss: 0.0965\n",
            "Epoch 395/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9179 - loss: 0.2315\n",
            "Epoch 395: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9155 - loss: 0.2352 - val_accuracy: 0.9689 - val_loss: 0.0798\n",
            "Epoch 396/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8904 - loss: 0.2821\n",
            "Epoch 396: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8904 - loss: 0.2828 - val_accuracy: 0.9516 - val_loss: 0.1097\n",
            "Epoch 397/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9011 - loss: 0.2700\n",
            "Epoch 397: val_loss did not improve from 0.07277\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9029 - loss: 0.2677 - val_accuracy: 0.9792 - val_loss: 0.0732\n",
            "Epoch 398/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9177 - loss: 0.2757\n",
            "Epoch 398: val_loss improved from 0.07277 to 0.06534, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9159 - loss: 0.2778 - val_accuracy: 0.9896 - val_loss: 0.0653\n",
            "Epoch 399/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9109 - loss: 0.2695\n",
            "Epoch 399: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9122 - loss: 0.2666 - val_accuracy: 0.9654 - val_loss: 0.0921\n",
            "Epoch 400/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9130 - loss: 0.2514\n",
            "Epoch 400: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9125 - loss: 0.2529 - val_accuracy: 0.9758 - val_loss: 0.0781\n",
            "Epoch 401/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9178 - loss: 0.2483\n",
            "Epoch 401: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9161 - loss: 0.2509 - val_accuracy: 0.9619 - val_loss: 0.1095\n",
            "Epoch 402/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9228 - loss: 0.2172\n",
            "Epoch 402: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9228 - loss: 0.2202 - val_accuracy: 0.9585 - val_loss: 0.1017\n",
            "Epoch 403/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9022 - loss: 0.2850\n",
            "Epoch 403: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9035 - loss: 0.2843 - val_accuracy: 0.9308 - val_loss: 0.1455\n",
            "Epoch 404/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9113 - loss: 0.2821 \n",
            "Epoch 404: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9126 - loss: 0.2781 - val_accuracy: 0.9792 - val_loss: 0.0790\n",
            "Epoch 405/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9253 - loss: 0.2493\n",
            "Epoch 405: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9255 - loss: 0.2482 - val_accuracy: 0.9689 - val_loss: 0.1010\n",
            "Epoch 406/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8994 - loss: 0.2853\n",
            "Epoch 406: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8994 - loss: 0.2860 - val_accuracy: 0.9689 - val_loss: 0.0840\n",
            "Epoch 407/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9271 - loss: 0.2112\n",
            "Epoch 407: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9254 - loss: 0.2154 - val_accuracy: 0.9654 - val_loss: 0.0815\n",
            "Epoch 408/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9082 - loss: 0.2827\n",
            "Epoch 408: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9084 - loss: 0.2824 - val_accuracy: 0.9792 - val_loss: 0.0751\n",
            "Epoch 409/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9376 - loss: 0.2070\n",
            "Epoch 409: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9371 - loss: 0.2069 - val_accuracy: 0.9689 - val_loss: 0.0796\n",
            "Epoch 410/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9213 - loss: 0.2321\n",
            "Epoch 410: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9205 - loss: 0.2342 - val_accuracy: 0.9689 - val_loss: 0.0747\n",
            "Epoch 411/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9158 - loss: 0.2363\n",
            "Epoch 411: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9155 - loss: 0.2371 - val_accuracy: 0.9412 - val_loss: 0.1245\n",
            "Epoch 412/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9305 - loss: 0.2313\n",
            "Epoch 412: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9302 - loss: 0.2317 - val_accuracy: 0.9585 - val_loss: 0.0997\n",
            "Epoch 413/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9185 - loss: 0.2646\n",
            "Epoch 413: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9184 - loss: 0.2626 - val_accuracy: 0.9377 - val_loss: 0.1599\n",
            "Epoch 414/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9052 - loss: 0.2719\n",
            "Epoch 414: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9040 - loss: 0.2739 - val_accuracy: 0.9343 - val_loss: 0.1601\n",
            "Epoch 415/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9126 - loss: 0.2497\n",
            "Epoch 415: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9120 - loss: 0.2527 - val_accuracy: 0.9481 - val_loss: 0.1099\n",
            "Epoch 416/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8868 - loss: 0.3244\n",
            "Epoch 416: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8882 - loss: 0.3175 - val_accuracy: 0.9792 - val_loss: 0.0731\n",
            "Epoch 417/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.2397\n",
            "Epoch 417: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9241 - loss: 0.2411 - val_accuracy: 0.9758 - val_loss: 0.0667\n",
            "Epoch 418/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.2259\n",
            "Epoch 418: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9204 - loss: 0.2320 - val_accuracy: 0.9377 - val_loss: 0.1813\n",
            "Epoch 419/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9034 - loss: 0.2871\n",
            "Epoch 419: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9017 - loss: 0.2883 - val_accuracy: 0.9792 - val_loss: 0.0807\n",
            "Epoch 420/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8785 - loss: 0.3329\n",
            "Epoch 420: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8815 - loss: 0.3261 - val_accuracy: 0.9689 - val_loss: 0.0877\n",
            "Epoch 421/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9005 - loss: 0.2929\n",
            "Epoch 421: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9008 - loss: 0.2922 - val_accuracy: 0.9827 - val_loss: 0.0694\n",
            "Epoch 422/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9344 - loss: 0.2120\n",
            "Epoch 422: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9344 - loss: 0.2120 - val_accuracy: 0.9723 - val_loss: 0.0735\n",
            "Epoch 423/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9084 - loss: 0.2753\n",
            "Epoch 423: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9086 - loss: 0.2750 - val_accuracy: 0.9377 - val_loss: 0.1289\n",
            "Epoch 424/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8732 - loss: 0.3749\n",
            "Epoch 424: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8740 - loss: 0.3707 - val_accuracy: 0.9273 - val_loss: 0.1686\n",
            "Epoch 425/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8573 - loss: 0.4323\n",
            "Epoch 425: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8572 - loss: 0.4308 - val_accuracy: 0.9308 - val_loss: 0.1659\n",
            "Epoch 426/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8824 - loss: 0.3184\n",
            "Epoch 426: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8825 - loss: 0.3181 - val_accuracy: 0.9343 - val_loss: 0.1398\n",
            "Epoch 427/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8688 - loss: 0.3580\n",
            "Epoch 427: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8684 - loss: 0.3558 - val_accuracy: 0.9619 - val_loss: 0.1130\n",
            "Epoch 428/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9032 - loss: 0.2643\n",
            "Epoch 428: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9028 - loss: 0.2641 - val_accuracy: 0.9758 - val_loss: 0.0910\n",
            "Epoch 429/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9183 - loss: 0.2503\n",
            "Epoch 429: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9172 - loss: 0.2483 - val_accuracy: 0.9792 - val_loss: 0.0823\n",
            "Epoch 430/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9103 - loss: 0.2686\n",
            "Epoch 430: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9084 - loss: 0.2752 - val_accuracy: 0.9550 - val_loss: 0.1080\n",
            "Epoch 431/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8882 - loss: 0.3198\n",
            "Epoch 431: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8887 - loss: 0.3173 - val_accuracy: 0.9689 - val_loss: 0.1008\n",
            "Epoch 432/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8932 - loss: 0.3176\n",
            "Epoch 432: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8942 - loss: 0.3132 - val_accuracy: 0.9689 - val_loss: 0.0912\n",
            "Epoch 433/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8989 - loss: 0.2605\n",
            "Epoch 433: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8989 - loss: 0.2617 - val_accuracy: 0.9758 - val_loss: 0.0885\n",
            "Epoch 434/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8940 - loss: 0.2950\n",
            "Epoch 434: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8939 - loss: 0.2942 - val_accuracy: 0.9827 - val_loss: 0.0775\n",
            "Epoch 435/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8956 - loss: 0.2609\n",
            "Epoch 435: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8968 - loss: 0.2615 - val_accuracy: 0.9446 - val_loss: 0.1218\n",
            "Epoch 436/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9145 - loss: 0.2370\n",
            "Epoch 436: val_loss did not improve from 0.06534\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9141 - loss: 0.2378 - val_accuracy: 0.9446 - val_loss: 0.1286\n",
            "Epoch 437/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9040 - loss: 0.2534\n",
            "Epoch 437: val_loss improved from 0.06534 to 0.06389, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9041 - loss: 0.2555 - val_accuracy: 0.9792 - val_loss: 0.0639\n",
            "Epoch 438/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.2238\n",
            "Epoch 438: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9206 - loss: 0.2227 - val_accuracy: 0.9516 - val_loss: 0.1125\n",
            "Epoch 439/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9126 - loss: 0.2573\n",
            "Epoch 439: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9135 - loss: 0.2543 - val_accuracy: 0.9654 - val_loss: 0.0762\n",
            "Epoch 440/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2450\n",
            "Epoch 440: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9152 - loss: 0.2460 - val_accuracy: 0.9654 - val_loss: 0.0818\n",
            "Epoch 441/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9080 - loss: 0.2698\n",
            "Epoch 441: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9076 - loss: 0.2710 - val_accuracy: 0.9550 - val_loss: 0.1187\n",
            "Epoch 442/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9266 - loss: 0.2219\n",
            "Epoch 442: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9253 - loss: 0.2258 - val_accuracy: 0.9308 - val_loss: 0.1855\n",
            "Epoch 443/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8698 - loss: 0.3730\n",
            "Epoch 443: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8696 - loss: 0.3700 - val_accuracy: 0.8651 - val_loss: 0.2898\n",
            "Epoch 444/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8854 - loss: 0.3084\n",
            "Epoch 444: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8864 - loss: 0.3044 - val_accuracy: 0.9377 - val_loss: 0.1650\n",
            "Epoch 445/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8870 - loss: 0.2978\n",
            "Epoch 445: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8870 - loss: 0.2981 - val_accuracy: 0.9619 - val_loss: 0.1155\n",
            "Epoch 446/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9080 - loss: 0.2798\n",
            "Epoch 446: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9059 - loss: 0.2820 - val_accuracy: 0.9619 - val_loss: 0.1080\n",
            "Epoch 447/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9064 - loss: 0.2736\n",
            "Epoch 447: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9065 - loss: 0.2713 - val_accuracy: 0.9516 - val_loss: 0.1039\n",
            "Epoch 448/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9064 - loss: 0.2701\n",
            "Epoch 448: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9064 - loss: 0.2698 - val_accuracy: 0.9550 - val_loss: 0.1009\n",
            "Epoch 449/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8878 - loss: 0.3045\n",
            "Epoch 449: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8877 - loss: 0.3056 - val_accuracy: 0.9792 - val_loss: 0.1008\n",
            "Epoch 450/500\n",
            "\u001b[1m41/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8931 - loss: 0.3018\n",
            "Epoch 450: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8931 - loss: 0.3011 - val_accuracy: 0.9827 - val_loss: 0.0944\n",
            "Epoch 451/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8994 - loss: 0.2900\n",
            "Epoch 451: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8994 - loss: 0.2902 - val_accuracy: 0.9516 - val_loss: 0.1108\n",
            "Epoch 452/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8960 - loss: 0.2849\n",
            "Epoch 452: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8936 - loss: 0.2915 - val_accuracy: 0.9308 - val_loss: 0.1385\n",
            "Epoch 453/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8946 - loss: 0.2687\n",
            "Epoch 453: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8953 - loss: 0.2684 - val_accuracy: 0.9550 - val_loss: 0.1236\n",
            "Epoch 454/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8853 - loss: 0.2915\n",
            "Epoch 454: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8863 - loss: 0.2913 - val_accuracy: 0.9619 - val_loss: 0.0953\n",
            "Epoch 455/500\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8819 - loss: 0.3103\n",
            "Epoch 455: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8827 - loss: 0.3085 - val_accuracy: 0.9619 - val_loss: 0.0982\n",
            "Epoch 456/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9035 - loss: 0.2761\n",
            "Epoch 456: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9043 - loss: 0.2722 - val_accuracy: 0.9827 - val_loss: 0.0825\n",
            "Epoch 457/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9226 - loss: 0.2507\n",
            "Epoch 457: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9224 - loss: 0.2500 - val_accuracy: 0.9689 - val_loss: 0.0877\n",
            "Epoch 458/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9223 - loss: 0.2301\n",
            "Epoch 458: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9205 - loss: 0.2318 - val_accuracy: 0.9585 - val_loss: 0.0983\n",
            "Epoch 459/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9076 - loss: 0.2616\n",
            "Epoch 459: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9071 - loss: 0.2624 - val_accuracy: 0.9654 - val_loss: 0.0868\n",
            "Epoch 460/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9319 - loss: 0.2442\n",
            "Epoch 460: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9295 - loss: 0.2453 - val_accuracy: 0.9723 - val_loss: 0.0796\n",
            "Epoch 461/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9090 - loss: 0.2521\n",
            "Epoch 461: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9082 - loss: 0.2546 - val_accuracy: 0.9654 - val_loss: 0.1034\n",
            "Epoch 462/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9043 - loss: 0.2488\n",
            "Epoch 462: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9045 - loss: 0.2511 - val_accuracy: 0.9343 - val_loss: 0.1555\n",
            "Epoch 463/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8908 - loss: 0.2608\n",
            "Epoch 463: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8921 - loss: 0.2616 - val_accuracy: 0.9723 - val_loss: 0.0884\n",
            "Epoch 464/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9126 - loss: 0.2655\n",
            "Epoch 464: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9127 - loss: 0.2646 - val_accuracy: 0.9343 - val_loss: 0.1370\n",
            "Epoch 465/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8967 - loss: 0.3073\n",
            "Epoch 465: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8972 - loss: 0.3066 - val_accuracy: 0.9758 - val_loss: 0.0988\n",
            "Epoch 466/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9035 - loss: 0.2285\n",
            "Epoch 466: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9038 - loss: 0.2303 - val_accuracy: 0.9619 - val_loss: 0.0897\n",
            "Epoch 467/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8871 - loss: 0.3286\n",
            "Epoch 467: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8894 - loss: 0.3230 - val_accuracy: 0.9550 - val_loss: 0.1144\n",
            "Epoch 468/500\n",
            "\u001b[1m34/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9035 - loss: 0.2604\n",
            "Epoch 468: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9034 - loss: 0.2618 - val_accuracy: 0.9377 - val_loss: 0.1540\n",
            "Epoch 469/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9084 - loss: 0.2662\n",
            "Epoch 469: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9075 - loss: 0.2679 - val_accuracy: 0.9723 - val_loss: 0.0865\n",
            "Epoch 470/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9116 - loss: 0.2354\n",
            "Epoch 470: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9116 - loss: 0.2371 - val_accuracy: 0.9481 - val_loss: 0.1087\n",
            "Epoch 471/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9135 - loss: 0.2475\n",
            "Epoch 471: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9131 - loss: 0.2490 - val_accuracy: 0.9689 - val_loss: 0.0976\n",
            "Epoch 472/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9145 - loss: 0.2498\n",
            "Epoch 472: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9147 - loss: 0.2489 - val_accuracy: 0.9723 - val_loss: 0.0876\n",
            "Epoch 473/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9177 - loss: 0.2462\n",
            "Epoch 473: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9168 - loss: 0.2471 - val_accuracy: 0.9723 - val_loss: 0.1008\n",
            "Epoch 474/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9199 - loss: 0.2452\n",
            "Epoch 474: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9185 - loss: 0.2458 - val_accuracy: 0.9723 - val_loss: 0.0939\n",
            "Epoch 475/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9092 - loss: 0.2647\n",
            "Epoch 475: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9086 - loss: 0.2671 - val_accuracy: 0.9516 - val_loss: 0.1148\n",
            "Epoch 476/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8975 - loss: 0.2968\n",
            "Epoch 476: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9006 - loss: 0.2926 - val_accuracy: 0.9481 - val_loss: 0.0920\n",
            "Epoch 477/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9132 - loss: 0.2686\n",
            "Epoch 477: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9109 - loss: 0.2751 - val_accuracy: 0.9550 - val_loss: 0.1095\n",
            "Epoch 478/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9124 - loss: 0.2294\n",
            "Epoch 478: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9122 - loss: 0.2311 - val_accuracy: 0.9343 - val_loss: 0.1892\n",
            "Epoch 479/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9066 - loss: 0.2823\n",
            "Epoch 479: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9071 - loss: 0.2788 - val_accuracy: 0.9689 - val_loss: 0.0793\n",
            "Epoch 480/500\n",
            "\u001b[1m40/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9222 - loss: 0.2556\n",
            "Epoch 480: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9225 - loss: 0.2533 - val_accuracy: 0.9550 - val_loss: 0.0836\n",
            "Epoch 481/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9336 - loss: 0.1863\n",
            "Epoch 481: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9312 - loss: 0.1944 - val_accuracy: 0.9723 - val_loss: 0.0792\n",
            "Epoch 482/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9355 - loss: 0.2094\n",
            "Epoch 482: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9352 - loss: 0.2099 - val_accuracy: 0.9619 - val_loss: 0.0853\n",
            "Epoch 483/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9228 - loss: 0.2220\n",
            "Epoch 483: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9220 - loss: 0.2221 - val_accuracy: 0.9343 - val_loss: 0.1516\n",
            "Epoch 484/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8930 - loss: 0.3208\n",
            "Epoch 484: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8951 - loss: 0.3141 - val_accuracy: 0.9723 - val_loss: 0.0876\n",
            "Epoch 485/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.2399\n",
            "Epoch 485: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9174 - loss: 0.2402 - val_accuracy: 0.9792 - val_loss: 0.0768\n",
            "Epoch 486/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8965 - loss: 0.2517\n",
            "Epoch 486: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8980 - loss: 0.2518 - val_accuracy: 0.9792 - val_loss: 0.0709\n",
            "Epoch 487/500\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9250 - loss: 0.2559\n",
            "Epoch 487: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9247 - loss: 0.2563 - val_accuracy: 0.9585 - val_loss: 0.0885\n",
            "Epoch 488/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9124 - loss: 0.2365\n",
            "Epoch 488: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9111 - loss: 0.2384 - val_accuracy: 0.9758 - val_loss: 0.0719\n",
            "Epoch 489/500\n",
            "\u001b[1m38/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9246 - loss: 0.2211\n",
            "Epoch 489: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9240 - loss: 0.2218 - val_accuracy: 0.9689 - val_loss: 0.0857\n",
            "Epoch 490/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9119 - loss: 0.2351\n",
            "Epoch 490: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9116 - loss: 0.2352 - val_accuracy: 0.9758 - val_loss: 0.0788\n",
            "Epoch 491/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9321 - loss: 0.1983\n",
            "Epoch 491: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9299 - loss: 0.2037 - val_accuracy: 0.9619 - val_loss: 0.0882\n",
            "Epoch 492/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9210 - loss: 0.2239\n",
            "Epoch 492: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9198 - loss: 0.2266 - val_accuracy: 0.9516 - val_loss: 0.0857\n",
            "Epoch 493/500\n",
            "\u001b[1m39/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9033 - loss: 0.2803\n",
            "Epoch 493: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9026 - loss: 0.2816 - val_accuracy: 0.9516 - val_loss: 0.1036\n",
            "Epoch 494/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9049 - loss: 0.2716\n",
            "Epoch 494: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9049 - loss: 0.2696 - val_accuracy: 0.9689 - val_loss: 0.0747\n",
            "Epoch 495/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9185 - loss: 0.2247\n",
            "Epoch 495: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9174 - loss: 0.2284 - val_accuracy: 0.9446 - val_loss: 0.1590\n",
            "Epoch 496/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9027 - loss: 0.2529\n",
            "Epoch 496: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9040 - loss: 0.2518 - val_accuracy: 0.9758 - val_loss: 0.0689\n",
            "Epoch 497/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9128 - loss: 0.2546\n",
            "Epoch 497: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9129 - loss: 0.2561 - val_accuracy: 0.9758 - val_loss: 0.0871\n",
            "Epoch 498/500\n",
            "\u001b[1m37/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9140 - loss: 0.2362\n",
            "Epoch 498: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9132 - loss: 0.2375 - val_accuracy: 0.9689 - val_loss: 0.0802\n",
            "Epoch 499/500\n",
            "\u001b[1m36/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9176 - loss: 0.2359\n",
            "Epoch 499: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9179 - loss: 0.2358 - val_accuracy: 0.9689 - val_loss: 0.0673\n",
            "Epoch 500/500\n",
            "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9177 - loss: 0.2197\n",
            "Epoch 500: val_loss did not improve from 0.06389\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9186 - loss: 0.2239 - val_accuracy: 0.9654 - val_loss: 0.0930\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === VISUALISASI TRAINING ===\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss', color='orange')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy', color='orange')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "XB8JZWjuuanZ",
        "outputId": "db882de4-c56c-43bd-ef51-1b66249bc608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CONFUSION MATRIX ===\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=y_test_label_names,\n",
        "            yticklabels=y_test_label_names)\n",
        "plt.title('Confusion Matrix - Test Data')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "bKTkT4iaxFoj",
        "outputId": "0f4d6f7a-13e1-490d-d1ad-a71facb4f37f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "import numpy as np\n",
        "\n",
        "def predict_sample_silent(kategori_str, rpn_val):\n",
        "    # Preprocess input\n",
        "    k_enc = le_kat.transform([kategori_str])[0]\n",
        "    r_scaled = scaler.transform([[rpn_val]])[0][0]\n",
        "\n",
        "    X_new = np.array([[k_enc, r_scaled]])\n",
        "\n",
        "    # Load model terbaik\n",
        "    model_loaded = load_model('best_model.h5')\n",
        "\n",
        "    # Predict\n",
        "    y_proba = model_loaded.predict(X_new)\n",
        "    y_idx = np.argmax(y_proba, axis=1)[0]\n",
        "    y_label = le_resiko.inverse_transform([y_idx])[0]\n",
        "\n",
        "    # Cetak hasil prediksi dan probabilitas\n",
        "    print(\"Predicted label:\", y_label)\n",
        "    print(\"Probabilities:\", y_proba)\n",
        "\n",
        "    return y_label, y_proba\n",
        "\n",
        "label, proba = predict_sample_silent('3', 1000) #('Kategori', Nilai RPN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9zui-tTx6GE",
        "outputId": "3774dc51-dd75-458d-dc2b-d5095f7786c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:6 out of the last 14 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dfd749a5c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step\n",
            "Predicted label: 4\n",
            "Probabilities: [[1.5451306e-08 8.6119877e-07 1.4571422e-07 1.1413075e-02 9.8858589e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "import pickle\n",
        "data_input = np.array([\n",
        "    ['1', 600],\n",
        "    ['2', 128],\n",
        "    ['3', 157],\n",
        "    ['4', 185],\n",
        "    ['5', 214],\n",
        "    ['6', 242],\n",
        "    ['7', 271],\n",
        "    ['8', 300],\n",
        "    ['9', 328],\n",
        "    ['10', 357],\n",
        "    ['11', 385],\n",
        "    ['12', 414],\n",
        "    ['13', 442],\n",
        "    ['14', 471],\n",
        "    ['15', 500],\n",
        "    ['16', 528],\n",
        "    ['17', 557],\n",
        "    ['18', 585],\n",
        "    ['19', 614],\n",
        "    ['20', 642],\n",
        "    ['21', 671],\n",
        "    ['22', 700],\n",
        "    ['23', 728],\n",
        "    ['24', 757],\n",
        "    ['25', 785],\n",
        "    ['26', 814],\n",
        "    ['27', 842],\n",
        "    ['28', 871],\n",
        "    ['29', 900],\n",
        "    ['30', 928],\n",
        "    ['31', 957],\n",
        "    ['32', 985],\n",
        "    ['33', 1014],\n",
        "    ['34', 1042],\n",
        "    ['35', 1071]\n",
        "], dtype=object)\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Pakai data_input di atas\n",
        "\n",
        "model_loaded = load_model('best_model.h5')\n",
        "\n",
        "def predict_sample(kategori_str, rpn_val):\n",
        "    k_enc = le_kat.transform([kategori_str])[0]\n",
        "    r_scaled = scaler.transform([[rpn_val]])[0][0]\n",
        "\n",
        "    with open('label_encoder.pkl', 'wb') as f:\n",
        "        pickle.dump(le_kat, f)\n",
        "\n",
        "    with open('scaler.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "    X_new = np.array([[k_enc, r_scaled]])\n",
        "\n",
        "    y_proba = model_loaded.predict(X_new)\n",
        "    y_idx = np.argmax(y_proba, axis=1)[0]\n",
        "    y_label = le_resiko.inverse_transform([y_idx])[0]\n",
        "\n",
        "    return y_label, y_proba\n",
        "\n",
        "indices_with_label_4 = []\n",
        "\n",
        "for i, (kat, rpn) in enumerate(data_input):\n",
        "    label, proba = predict_sample(kat, float(rpn))  # pastikan rpn jadi float\n",
        "    print(f\"Index {i} - Input: (Kategori: {kat}, RPN: {float(rpn):.2f}) => Predicted: {label}\")\n",
        "    print(f\"  Probabilities: {proba}\")\n",
        "\n",
        "    if str(label) == \"4\":  # gunakan str untuk memastikan kecocokan\n",
        "        indices_with_label_4.append(i)\n",
        "\n",
        "print(\"Indices of inputs with predicted label '4':\", indices_with_label_4)\n",
        "\n",
        "mitigasi_list = [\n",
        "    \"Penyusunan Non-Disclosure Agreement (NDA)\",\n",
        "    \"Diversifikasi produk, saluran pemasaran, dan segmen pasar\",\n",
        "    \"Simplifikasi rantai pasok\",\n",
        "    \"Penyusunan SOP\",\n",
        "    \"Diversifikasi produk, saluran pemasaran, dan segmen pasar\",\n",
        "    \"Optimasi kapasitas penyimpanan\",\n",
        "    \"Diversifikasi produk, saluran pemasaran, dan segmen pasar\",\n",
        "    \"Optimasi jalur distribusi\",\n",
        "    \"Diversifikasi produk, saluran pemasaran, dan segmen pasar\",\n",
        "    \"Penerapan Good Agriculture Practice (GAP)\",\n",
        "    \"Penerapan kalender pennaman adaptif\",\n",
        "    \"Penyusunan SOP\",\n",
        "    \"Penerapan program penghijauan\",\n",
        "    \"Asuransi\",\n",
        "    \"Asuransi\",\n",
        "    \"Penerapan Good Agriculture Practice (GAP)\",\n",
        "    \"Penerapan Good Agriculture Practice (GAP)\",\n",
        "    \"Penyusunan SOP\",\n",
        "    \"Penyusunan SOP\",\n",
        "    \"Penyusunan Non-Disclosure Agreement (NDA)\",\n",
        "    \"Penerapan Good Agriculture Practice (GAP)\",\n",
        "    \"Pencatatan digital yang terjadwal\",\n",
        "    \"Perekrutan Tenaga Kerja Waktu Tertentu (PKWT)\",\n",
        "    \"Penyusunan kontrak dengan supplier\",\n",
        "    \"Penyusunan SOP\",\n",
        "    \"Diversifikasi produk, saluran pemasaran, dan segmen pasar\",\n",
        "    \"Diversifikasi produk, saluran pemasaran, dan segmen pasar\",\n",
        "    \"Pencatatan digital yang terjadwal\",\n",
        "    \"Penyusunan SOP\",\n",
        "    \"Pelatihan dan pengembangan keterampilan petani\",\n",
        "    \"Penyusunan SOP\",\n",
        "    \"Penerapan Good Agriculture Practice (GAP)\",\n",
        "    \"Diversifikasi produk, saluran pemasaran, dan segmen pasar\",\n",
        "    \"Penyusunan SOP\",\n",
        "    \"Penyusunan SOP\"\n",
        "]\n",
        "\n",
        "\n",
        "for idx in indices_with_label_4:\n",
        "    if 0 <= idx < len(mitigasi_list):\n",
        "        print(f\"Index {idx}: {mitigasi_list[idx]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IhHQVUrzl6Z",
        "outputId": "b6aa0e9e-66e2-4b32-a0ef-edee512146cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step\n",
            "Index 0 - Input: (Kategori: 1, RPN: 600.00) => Predicted: 4\n",
            "  Probabilities: [[1.1901072e-05 2.3999719e-06 3.6539524e-07 1.8164434e-02 9.8182088e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Index 1 - Input: (Kategori: 2, RPN: 128.00) => Predicted: 2\n",
            "  Probabilities: [[8.2474347e-04 5.5466029e-03 9.8824126e-01 5.3792624e-03 8.1645203e-06]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Index 2 - Input: (Kategori: 3, RPN: 157.00) => Predicted: 2\n",
            "  Probabilities: [[8.3821727e-04 4.9455529e-03 9.8485422e-01 9.3488311e-03 1.3103004e-05]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Index 3 - Input: (Kategori: 4, RPN: 185.00) => Predicted: 2\n",
            "  Probabilities: [[1.0276245e-03 5.6586983e-03 9.7725767e-01 1.6034376e-02 2.1698192e-05]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Index 4 - Input: (Kategori: 5, RPN: 214.00) => Predicted: 3\n",
            "  Probabilities: [[3.7257199e-04 1.0005091e-03 6.1987579e-02 9.3470114e-01 1.9382311e-03]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
            "Index 5 - Input: (Kategori: 6, RPN: 242.00) => Predicted: 3\n",
            "  Probabilities: [[7.2742929e-05 2.2054646e-04 1.7123424e-02 9.8089671e-01 1.6866182e-03]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Index 6 - Input: (Kategori: 7, RPN: 271.00) => Predicted: 3\n",
            "  Probabilities: [[5.6495272e-05 1.8134710e-04 1.3897379e-02 9.8416728e-01 1.6975265e-03]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Index 7 - Input: (Kategori: 8, RPN: 300.00) => Predicted: 3\n",
            "  Probabilities: [[5.4507804e-05 1.7019961e-04 1.2221158e-02 9.8568732e-01 1.8668345e-03]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Index 8 - Input: (Kategori: 9, RPN: 328.00) => Predicted: 3\n",
            "  Probabilities: [[5.0813742e-05 1.5680301e-04 1.0825641e-02 9.8693556e-01 2.0310974e-03]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Index 9 - Input: (Kategori: 10, RPN: 357.00) => Predicted: 3\n",
            "  Probabilities: [[4.8811733e-05 1.4724201e-04 9.4208699e-03 9.8809892e-01 2.2842109e-03]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Index 10 - Input: (Kategori: 11, RPN: 385.00) => Predicted: 3\n",
            "  Probabilities: [[5.7027988e-05 1.5976075e-04 8.3395336e-03 9.8857445e-01 2.8692272e-03]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "Index 11 - Input: (Kategori: 12, RPN: 414.00) => Predicted: 3\n",
            "  Probabilities: [[9.5228599e-05 2.1041410e-04 5.8406265e-03 9.8790622e-01 5.9475130e-03]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "Index 12 - Input: (Kategori: 13, RPN: 442.00) => Predicted: 3\n",
            "  Probabilities: [[1.9847459e-04 3.0906784e-04 3.2529132e-03 9.7796702e-01 1.8272448e-02]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 13 - Input: (Kategori: 14, RPN: 471.00) => Predicted: 3\n",
            "  Probabilities: [[3.7854246e-04 4.1052166e-04 1.4899195e-03 9.3195099e-01 6.5770097e-02]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "Index 14 - Input: (Kategori: 15, RPN: 500.00) => Predicted: 3\n",
            "  Probabilities: [[5.9599726e-04 4.8925309e-04 4.3431221e-04 6.8864769e-01 3.0983278e-01]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "Index 15 - Input: (Kategori: 16, RPN: 528.00) => Predicted: 4\n",
            "  Probabilities: [[3.1260942e-04 1.2449664e-04 3.5699002e-05 1.9823205e-01 8.0129510e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
            "Index 16 - Input: (Kategori: 17, RPN: 557.00) => Predicted: 4\n",
            "  Probabilities: [[1.0283259e-04 3.1209318e-05 6.9640523e-06 8.5140400e-02 9.1471857e-01]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
            "Index 17 - Input: (Kategori: 18, RPN: 585.00) => Predicted: 4\n",
            "  Probabilities: [[3.2862066e-05 8.1706821e-06 1.5225393e-06 3.9241243e-02 9.6071625e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
            "Index 18 - Input: (Kategori: 19, RPN: 614.00) => Predicted: 4\n",
            "  Probabilities: [[9.9971339e-06 2.0202981e-06 3.1135826e-07 1.7169375e-02 9.8281831e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "Index 19 - Input: (Kategori: 20, RPN: 642.00) => Predicted: 4\n",
            "  Probabilities: [[2.8789768e-06 4.8697683e-07 6.4632772e-08 7.7651255e-03 9.9223137e-01]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "Index 20 - Input: (Kategori: 21, RPN: 671.00) => Predicted: 4\n",
            "  Probabilities: [[7.9714590e-07 1.1185175e-07 1.2667884e-08 3.3898256e-03 9.9660933e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 21 - Input: (Kategori: 22, RPN: 700.00) => Predicted: 4\n",
            "  Probabilities: [[2.1977262e-07 2.5480736e-08 2.4496909e-09 1.4626896e-03 9.9853706e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 22 - Input: (Kategori: 23, RPN: 728.00) => Predicted: 4\n",
            "  Probabilities: [[6.3292802e-08 6.2491341e-09 4.9500548e-10 6.4015895e-04 9.9935979e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 23 - Input: (Kategori: 24, RPN: 757.00) => Predicted: 4\n",
            "  Probabilities: [[1.7368615e-08 1.4559366e-09 9.4653764e-11 2.7293598e-04 9.9972707e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Index 24 - Input: (Kategori: 25, RPN: 785.00) => Predicted: 4\n",
            "  Probabilities: [[5.00730657e-09 3.58625241e-10 1.92830057e-11 1.20223565e-04\n",
            "  9.99879718e-01]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "Index 25 - Input: (Kategori: 26, RPN: 814.00) => Predicted: 4\n",
            "  Probabilities: [[1.3660687e-09 8.2916916e-11 3.6545289e-12 5.0985476e-05 9.9994898e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Index 26 - Input: (Kategori: 27, RPN: 842.00) => Predicted: 4\n",
            "  Probabilities: [[3.8626002e-10 2.0011052e-11 7.2969397e-13 2.2267281e-05 9.9997771e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Index 27 - Input: (Kategori: 28, RPN: 871.00) => Predicted: 4\n",
            "  Probabilities: [[1.0473943e-10 4.5988760e-12 1.3758031e-13 9.4276829e-06 9.9999058e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 28 - Input: (Kategori: 29, RPN: 900.00) => Predicted: 4\n",
            "  Probabilities: [[2.8081289e-11 1.0463387e-12 2.5704396e-14 3.9816659e-06 9.9999607e-01]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
            "Index 29 - Input: (Kategori: 30, RPN: 928.00) => Predicted: 4\n",
            "  Probabilities: [[7.7688567e-12 2.4742955e-13 5.0328771e-15 1.7275470e-06 9.9999833e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Index 30 - Input: (Kategori: 31, RPN: 957.00) => Predicted: 4\n",
            "  Probabilities: [[2.0457254e-12 5.5365323e-14 9.2591067e-16 7.2611743e-07 9.9999928e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 31 - Input: (Kategori: 32, RPN: 985.00) => Predicted: 4\n",
            "  Probabilities: [[5.65731218e-13 1.30872155e-14 1.81222951e-16 3.15001557e-07\n",
            "  9.99999642e-01]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "Index 32 - Input: (Kategori: 33, RPN: 1014.00) => Predicted: 4\n",
            "  Probabilities: [[1.4897129e-13 2.9284303e-15 3.3340004e-17 1.3240069e-07 9.9999988e-01]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Index 33 - Input: (Kategori: 34, RPN: 1042.00) => Predicted: 4\n",
            "  Probabilities: [[4.1197128e-14 6.9222280e-16 6.5254624e-18 5.7437891e-08 1.0000000e+00]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Index 34 - Input: (Kategori: 35, RPN: 1071.00) => Predicted: 4\n",
            "  Probabilities: [[1.1117450e-14 1.5673736e-16 1.2027089e-18 2.3859199e-08 1.0000000e+00]]\n",
            "Indices of inputs with predicted label '4': [0, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "Index 0: Penyusunan Non-Disclosure Agreement (NDA)\n",
            "Index 15: Penerapan Good Agriculture Practice (GAP)\n",
            "Index 16: Penerapan Good Agriculture Practice (GAP)\n",
            "Index 17: Penyusunan SOP\n",
            "Index 18: Penyusunan SOP\n",
            "Index 19: Penyusunan Non-Disclosure Agreement (NDA)\n",
            "Index 20: Penerapan Good Agriculture Practice (GAP)\n",
            "Index 21: Pencatatan digital yang terjadwal\n",
            "Index 22: Perekrutan Tenaga Kerja Waktu Tertentu (PKWT)\n",
            "Index 23: Penyusunan kontrak dengan supplier\n",
            "Index 24: Penyusunan SOP\n",
            "Index 25: Diversifikasi produk, saluran pemasaran, dan segmen pasar\n",
            "Index 26: Diversifikasi produk, saluran pemasaran, dan segmen pasar\n",
            "Index 27: Pencatatan digital yang terjadwal\n",
            "Index 28: Penyusunan SOP\n",
            "Index 29: Pelatihan dan pengembangan keterampilan petani\n",
            "Index 30: Penyusunan SOP\n",
            "Index 31: Penerapan Good Agriculture Practice (GAP)\n",
            "Index 32: Diversifikasi produk, saluran pemasaran, dan segmen pasar\n",
            "Index 33: Penyusunan SOP\n",
            "Index 34: Penyusunan SOP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2117R-xyOyu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}